{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ashwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# %load process_tweet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def process_tweet(tweet, tknzr, advanced=False):\n",
    "    st_1 = []\n",
    "    for w in tknzr.tokenize(tweet):\n",
    "        #remove retweet annotation if present:\n",
    "        if w == 'RT':\n",
    "            if advanced:\n",
    "                st_1.append('rt')\n",
    "        elif w[0] == '@':\n",
    "            if advanced:\n",
    "                st_1.append('<user>')\n",
    "        #remove hashtag symbol\n",
    "        elif w[0] == '#':\n",
    "            st_1.append(w[1:])\n",
    "        #replace link with LINK keyword\n",
    "        elif w[:4] == 'http':\n",
    "            st_1.append('<url>')\n",
    "        elif w.isnumeric():\n",
    "            if advanced:\n",
    "                st_1.append('<number>')\n",
    "        else:\n",
    "            st_1.append(w)\n",
    "    \n",
    "    st_2 = []\n",
    "    \n",
    "    #remove stop words and punctuation, make everything lowercase\n",
    "    if advanced:\n",
    "        st_2 = [w.lower() for w in st_1 if is_valid_token(w) and \n",
    "                    not w.lower() in stop_words]\n",
    "    else:\n",
    "        st_2 = [w.lower() for w in st_1 if w.isalpha() and\n",
    "                not w.lower() in stop_words]\n",
    "    \n",
    "    #lemmatization (converts all words to root form for standardization)\n",
    "    lem = WordNetLemmatizer()\n",
    "    st_3 = list(map(lambda x: lem.lemmatize(x, pos='v'), st_2))\n",
    "    \n",
    "    #now do word segmentation/spell check\n",
    "    return ' '.join(st_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>Urgency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More millions in #Afghanistan even with ZERO a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These are the last post my brother made on soc...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In @cityofcc listening to local officials abou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So so so damn proud of @5ugarcane who is tirel...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can you help with #Harvey disaster respons...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Relevancy  Urgency\n",
       "0  More millions in #Afghanistan even with ZERO a...          0        0\n",
       "1  These are the last post my brother made on soc...          2        1\n",
       "2  In @cityofcc listening to local officials abou...          0        0\n",
       "3  So so so damn proud of @5ugarcane who is tirel...          3        0\n",
       "4  How can you help with #Harvey disaster respons...          0        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now read in raw labeled tweets\n",
    "df = pd.read_csv('data/labeled_prelim.csv').dropna()\n",
    "df = df.astype({'Relevancy':np.int32, 'Urgency':np.int32})\n",
    "df = df.reset_index(drop=True)\n",
    "df.pop('Id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>Urgency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>millions afghanistan even zero attack isis sym...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last post brother make social media phone go v...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>listen local officials epa help harvey response</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>damn proud tirelessly help fellow texans affec...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help harvey disaster response help victims nat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Relevancy  Urgency\n",
       "0  millions afghanistan even zero attack isis sym...          0        0\n",
       "1  last post brother make social media phone go v...          2        1\n",
       "2    listen local officials epa help harvey response          0        0\n",
       "3  damn proud tirelessly help fellow texans affec...          3        0\n",
       "4  help harvey disaster response help victims nat...          0        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now preprocess the tweets\n",
    "# sym_spell = create_symspell(2,7,'data/frequency_dictionary_en_82_765.txt')\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "df['Text'] = df['Text'].map(lambda x: process_tweet(x, tknzr, False))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next goal is to extract a bunch of features from the data and use feature selection methods to reduce the dimensionality of the data. This work is based on the research of Krouska et al. These are the features that will be extracted:\n",
    "* tf-idf\n",
    "* n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf-idf: 0</th>\n",
       "      <th>tf-idf: 1</th>\n",
       "      <th>tf-idf: 2</th>\n",
       "      <th>tf-idf: 3</th>\n",
       "      <th>tf-idf: 4</th>\n",
       "      <th>tf-idf: 5</th>\n",
       "      <th>tf-idf: 6</th>\n",
       "      <th>tf-idf: 7</th>\n",
       "      <th>tf-idf: 8</th>\n",
       "      <th>tf-idf: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>tf-idf: 3297</th>\n",
       "      <th>tf-idf: 3298</th>\n",
       "      <th>tf-idf: 3299</th>\n",
       "      <th>tf-idf: 3300</th>\n",
       "      <th>tf-idf: 3301</th>\n",
       "      <th>tf-idf: 3302</th>\n",
       "      <th>tf-idf: 3303</th>\n",
       "      <th>tf-idf: 3304</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>Urgency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tf-idf: 0  tf-idf: 1  tf-idf: 2  tf-idf: 3  tf-idf: 4  tf-idf: 5  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   tf-idf: 6  tf-idf: 7  tf-idf: 8  tf-idf: 9   ...     tf-idf: 3297  \\\n",
       "0        0.0        0.0        0.0        0.0   ...              0.0   \n",
       "1        0.0        0.0        0.0        0.0   ...              0.0   \n",
       "2        0.0        0.0        0.0        0.0   ...              0.0   \n",
       "3        0.0        0.0        0.0        0.0   ...              0.0   \n",
       "4        0.0        0.0        0.0        0.0   ...              0.0   \n",
       "\n",
       "   tf-idf: 3298  tf-idf: 3299  tf-idf: 3300  tf-idf: 3301  tf-idf: 3302  \\\n",
       "0           0.0           0.0           0.0           0.0      0.323127   \n",
       "1           0.0           0.0           0.0           0.0      0.000000   \n",
       "2           0.0           0.0           0.0           0.0      0.000000   \n",
       "3           0.0           0.0           0.0           0.0      0.000000   \n",
       "4           0.0           0.0           0.0           0.0      0.000000   \n",
       "\n",
       "   tf-idf: 3303  tf-idf: 3304  Relevancy  Urgency  \n",
       "0           0.0           0.0          0        0  \n",
       "1           0.0           0.0          2        1  \n",
       "2           0.0           0.0          0        0  \n",
       "3           0.0           0.0          3        0  \n",
       "4           0.0           0.0          0        0  \n",
       "\n",
       "[5 rows x 3307 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate tf-idf features and add to dataframe\n",
    "vectorizer = TfidfVectorizer()\n",
    "vecs = vectorizer.fit_transform(df['Text']).toarray()\n",
    "labels = list(map(lambda x: 'tf-idf: ' + str(x), range(vecs.shape[1])))\n",
    "\n",
    "df2 = pd.DataFrame(vecs, columns=labels)\n",
    "df2['Relevancy'] = df['Relevancy']\n",
    "df2['Urgency'] = df['Urgency']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': 5.779833889007568,\n",
       " 'score_time': 0.6838139057159424,\n",
       " 'test_accuracy': 0.965751323323544,\n",
       " 'test_precision': 0.33333333333333337,\n",
       " 'test_recall': 0.15333333333333332,\n",
       " 'test_f1': 0.1904812834224599,\n",
       " 'test_roc_auc': 0.6524034292366184}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import * \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import *\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_stats(model, X, y, cv, verbose=False):\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    auc = []\n",
    "        \n",
    "    cv_results = cross_validate(model, X, y, scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], \n",
    "                                cv=cv, return_train_score=False)\n",
    "    \n",
    "    new_results = {}\n",
    "    for k,v in cv_results.items():\n",
    "        new_results[k] = np.mean(v)\n",
    "    \n",
    "    if verbose:\n",
    "        print(new_results)\n",
    "    \n",
    "    #now return the data\n",
    "    return new_results\n",
    "\n",
    "df3 = df2.copy()\n",
    "df3.pop('Relevancy')\n",
    "labels = df3.pop('Urgency').map(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "get_stats(model, df3, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
