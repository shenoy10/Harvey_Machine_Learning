{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ashwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ashwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'process_tweet' from '/home/ashwin/Projects/Harvey_Machine_Learning/process_tweet.py'>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load process_tweet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "\n",
    "import process_tweet\n",
    "import importlib\n",
    "importlib.reload(process_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>Urgency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>247434</td>\n",
       "      <td>More millions in #Afghanistan even with ZERO a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>294115</td>\n",
       "      <td>These are the last post my brother made on soc...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24622</td>\n",
       "      <td>In @cityofcc listening to local officials abou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37807</td>\n",
       "      <td>So so so damn proud of @5ugarcane who is tirel...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37386</td>\n",
       "      <td>How can you help with #Harvey disaster respons...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                               Text  Relevancy  \\\n",
       "0  247434  More millions in #Afghanistan even with ZERO a...          0   \n",
       "1  294115  These are the last post my brother made on soc...          2   \n",
       "2   24622  In @cityofcc listening to local officials abou...          0   \n",
       "3   37807  So so so damn proud of @5ugarcane who is tirel...          3   \n",
       "4   37386  How can you help with #Harvey disaster respons...          0   \n",
       "\n",
       "   Urgency  \n",
       "0        0  \n",
       "1        1  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now read in raw labeled tweets\n",
    "df = pd.read_csv('data/labeled_prelim.csv').dropna()\n",
    "df = df.astype({'Relevancy':np.int32, 'Urgency':np.int32})\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now preprocess the tweets\n",
    "sym_spell = create_symspell(2,7,'data/frequency_dictionary_en_82_765.txt')\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'millions afghanistan even zero attack isis sympathizers invest texas nation build harvey texas flood'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['Text'].map(lambda x: process_tweet.process_tweet(x, tknzr, sym_spell))\n",
    "text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next goal is to extract a bunch of features from the data and use feature selection methods to reduce the dimensionality of the data. This work is based on the research of Krouska et al. These are the features that will be extracted:\n",
    "* tf-idf\n",
    "* n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf-idf: 0</th>\n",
       "      <th>tf-idf: 1</th>\n",
       "      <th>tf-idf: 2</th>\n",
       "      <th>tf-idf: 3</th>\n",
       "      <th>tf-idf: 4</th>\n",
       "      <th>tf-idf: 5</th>\n",
       "      <th>tf-idf: 6</th>\n",
       "      <th>tf-idf: 7</th>\n",
       "      <th>tf-idf: 8</th>\n",
       "      <th>tf-idf: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>tf-idf: 25373</th>\n",
       "      <th>tf-idf: 25374</th>\n",
       "      <th>tf-idf: 25375</th>\n",
       "      <th>tf-idf: 25376</th>\n",
       "      <th>tf-idf: 25377</th>\n",
       "      <th>tf-idf: 25378</th>\n",
       "      <th>tf-idf: 25379</th>\n",
       "      <th>tf-idf: 25380</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>Urgency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173237</td>\n",
       "      <td>0.173237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tf-idf: 0  tf-idf: 1  tf-idf: 2  tf-idf: 3  tf-idf: 4  tf-idf: 5  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   tf-idf: 6  tf-idf: 7  tf-idf: 8  tf-idf: 9   ...     tf-idf: 25373  \\\n",
       "0        0.0        0.0        0.0        0.0   ...          0.173237   \n",
       "1        0.0        0.0        0.0        0.0   ...          0.000000   \n",
       "2        0.0        0.0        0.0        0.0   ...          0.000000   \n",
       "3        0.0        0.0        0.0        0.0   ...          0.000000   \n",
       "4        0.0        0.0        0.0        0.0   ...          0.000000   \n",
       "\n",
       "   tf-idf: 25374  tf-idf: 25375  tf-idf: 25376  tf-idf: 25377  tf-idf: 25378  \\\n",
       "0       0.173237            0.0            0.0            0.0            0.0   \n",
       "1       0.000000            0.0            0.0            0.0            0.0   \n",
       "2       0.000000            0.0            0.0            0.0            0.0   \n",
       "3       0.000000            0.0            0.0            0.0            0.0   \n",
       "4       0.000000            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   tf-idf: 25379  tf-idf: 25380  Relevancy  Urgency  \n",
       "0            0.0            0.0          0        0  \n",
       "1            0.0            0.0          2        1  \n",
       "2            0.0            0.0          0        0  \n",
       "3            0.0            0.0          3        0  \n",
       "4            0.0            0.0          0        0  \n",
       "\n",
       "[5 rows x 25383 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate tf-idf features and add to dataframe\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "vecs = vectorizer.fit_transform(text).toarray()\n",
    "labels = list(map(lambda x: 'tf-idf: ' + str(x), range(vecs.shape[1])))\n",
    "\n",
    "df2 = pd.DataFrame(vecs, columns=labels)\n",
    "df2['Relevancy'] = df['Relevancy']\n",
    "df2['Urgency'] = df['Urgency']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': 5.779833889007568,\n",
       " 'score_time': 0.6838139057159424,\n",
       " 'test_accuracy': 0.965751323323544,\n",
       " 'test_precision': 0.33333333333333337,\n",
       " 'test_recall': 0.15333333333333332,\n",
       " 'test_f1': 0.1904812834224599,\n",
       " 'test_roc_auc': 0.6524034292366184}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import * \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import *\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_stats(model, X, y, cv, verbose=False):\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    auc = []\n",
    "        \n",
    "    cv_results = cross_validate(model, X, y, scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], \n",
    "                                cv=cv, return_train_score=False)\n",
    "    \n",
    "    new_results = {}\n",
    "    for k,v in cv_results.items():\n",
    "        new_results[k] = np.mean(v)\n",
    "    \n",
    "    if verbose:\n",
    "        print(new_results)\n",
    "    \n",
    "    #now return the data\n",
    "    return new_results\n",
    "\n",
    "df3 = df2.copy()\n",
    "df3.pop('Relevancy')\n",
    "labels = df3.pop('Urgency').map(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "get_stats(model, df3, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
