{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/amitjoshi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora, models\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from process_tweet import *\n",
    "\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import random\n",
    "import time\n",
    "\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>Urgency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>millions afghanistan even zero attack isis sym...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last post brother make social media phone go v...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>listen local officials epa help harvey respons...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>damn proud tirelessly help fellow texans affec...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help harvey disaster response help victims nat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Relevancy  Urgency\n",
       "0  millions afghanistan even zero attack isis sym...          0        0\n",
       "1  last post brother make social media phone go v...          2        1\n",
       "2  listen local officials epa help harvey respons...          0        0\n",
       "3  damn proud tirelessly help fellow texans affec...          3        0\n",
       "4  help harvey disaster response help victims nat...          0        0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/labeled_prelim_processed.csv')\n",
    "df = df.dropna()\n",
    "df.pop('Id')\n",
    "df = df.astype({'Relevancy':np.int32, 'Urgency':np.int32})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'millions afghanistan even zero attack isis sympathizers invest texas nation build harvey texasflood'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sym_spell = create_symspell(2,7,'data/frequency_dictionary_en_82_765.txt')\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "doc_sample = df['Text'][0]\n",
    "process_tweet(doc_sample, tknzr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty line\n"
     ]
    }
   ],
   "source": [
    "#list of embeddings\n",
    "vec_length = 50\n",
    "embeddings = np.zeros((1193514, vec_length))\n",
    "\n",
    "#two-way map, index->word and word->index\n",
    "glove = {}\n",
    "\n",
    "index = 0\n",
    "with open('data/glove.twitter.27B/glove.twitter.27B.%dd.txt' % vec_length) as f:\n",
    "    for l in f:\n",
    "        line = []\n",
    "        try:\n",
    "            line = l.split()\n",
    "            if len(line) != vec_length+1:\n",
    "                print('empty line')\n",
    "                continue\n",
    "            \n",
    "            word = line[0]\n",
    "            embeddings[index] = np.array(line[1:]).astype(np.float)\n",
    "            glove[index] = word\n",
    "            glove[word] = index\n",
    "            index += 1\n",
    "        except:\n",
    "            print(line)\n",
    "            print(index)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert columns to numpy arrays\n",
    "text = df['Text'].values\n",
    "relevancy = df['Relevancy'].values\n",
    "urgency = df['Urgency'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevancyClassifier(nn.Module):\n",
    "    def __init__(self, index, embeddings, embed_len, num_classes):\n",
    "        super(RelevancyClassifier, self).__init__()\n",
    "        self.hidden_size = 30\n",
    "        self.embed_len = embed_len\n",
    "        #print(embeddings.shape)\n",
    "        #self.embedding = nn.Embedding.from_pretrained(embeddings)\n",
    "        self.fc1 = nn.Linear(embed_len, self.hidden_size)\n",
    "        self.nl = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(self.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.nl(self.fc1(x)))\n",
    "\n",
    "def train_relevancy_classifier(train_exs, train_labels, embeddings, index):\n",
    "    try:\n",
    "        epochs = 100\n",
    "        lr = .0001\n",
    "        num_classes = 2\n",
    "        rc = RelevancyClassifier(index, embeddings, len(embeddings[0]), num_classes)\n",
    "        optimizer = optim.Adam(rc.parameters(), lr=lr)\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            ex_indices = [i for i in range(len(train_exs))]\n",
    "            random.shuffle(ex_indices)\n",
    "            total_loss = 0.0\n",
    "            num_tweets = len(ex_indices)\n",
    "            for idx in ex_indices:\n",
    "                cur_tweet = train_exs[idx]\n",
    "                cur_embed = []\n",
    "                for i in cur_tweet.split():\n",
    "                    if i in index:\n",
    "                        cur_embed.append(embeddings[index[i]])\n",
    "                if len(cur_embed) == 0:\n",
    "                    num_tweets -= 1\n",
    "                    continue\n",
    "                \n",
    "                x = torch.from_numpy(np.asarray(np.mean(cur_embed, axis=0)).reshape(1,vec_length)).float()\n",
    "                y = np.asarray(train_labels[idx]).reshape(1)\n",
    "                if y[0] > 0:\n",
    "                    y[0] = 1\n",
    "                y = torch.tensor(y).long()\n",
    "                rc.zero_grad()\n",
    "                probs = rc.forward(x)\n",
    "                cur_loss = loss(probs, y)\n",
    "                total_loss += cur_loss\n",
    "                cur_loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"Avg loss on epoch %i: %f\" % (epoch, total_loss/num_tweets))\n",
    "        return rc\n",
    "    except KeyboardInterrupt:\n",
    "        return rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'].values, relevancy, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss on epoch 0: 0.628518\n",
      "Avg loss on epoch 10: 0.485202\n",
      "Avg loss on epoch 20: 0.462517\n",
      "Avg loss on epoch 30: 0.450007\n",
      "Avg loss on epoch 40: 0.439678\n",
      "Avg loss on epoch 50: 0.428670\n",
      "Avg loss on epoch 60: 0.418403\n",
      "Avg loss on epoch 70: 0.408426\n",
      "Avg loss on epoch 80: 0.397423\n",
      "Avg loss on epoch 90: 0.387108\n"
     ]
    }
   ],
   "source": [
    "model = train_relevancy_classifier(X_train, y_train, embeddings, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.766260\n",
      "precision: 0.483146\n",
      "recall: 0.383929\n",
      "f1: 0.427861\n"
     ]
    }
   ],
   "source": [
    "val_tweets = X_test\n",
    "val_labels = y_test\n",
    "for i in range(len(val_labels)):\n",
    "    if val_labels[i] > 0:\n",
    "        val_labels[i] = 1\n",
    "\n",
    "num_correct = 0\n",
    "num_true_pos = 0\n",
    "num_false_pos = 0\n",
    "num_false_neg = 0\n",
    "\n",
    "for i in range(len(val_tweets)):\n",
    "    cur_embed = []\n",
    "    cur_tweet = val_tweets[i]\n",
    "    cur_label = val_labels[i]\n",
    "    for i in cur_tweet.split():\n",
    "        if i in glove:\n",
    "            cur_embed.append(embeddings[glove[i]])\n",
    "    if len(cur_embed) == 0:\n",
    "        continue\n",
    "    x = torch.from_numpy(np.asarray(np.mean(cur_embed, axis=0)).reshape(1,vec_length)).float()\n",
    "    probs = model.forward(x).detach().numpy().reshape(2)\n",
    "    pred_label = np.argmax(probs)\n",
    "    if pred_label == cur_label:\n",
    "        num_correct += 1\n",
    "        if pred_label > 0:\n",
    "            num_true_pos += 1\n",
    "    else:\n",
    "        if pred_label == 0:\n",
    "            num_false_neg += 1\n",
    "        else:\n",
    "            num_false_pos += 1\n",
    "\n",
    "accuracy = num_correct/len(val_tweets)\n",
    "precision = num_true_pos/(num_true_pos + num_false_pos)\n",
    "recall = num_true_pos/(num_true_pos + num_false_neg)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "\n",
    "print('accuracy: %f' % accuracy)\n",
    "print('precision: %f' % precision)\n",
    "print('recall: %f' % recall)\n",
    "print('f1: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only handles binary classification for now\n",
    "def tweets_to_df(df, labels, embeddings, glove):\n",
    "    \n",
    "    weights = []\n",
    "    index_omit = []\n",
    "    index = -1\n",
    "    tweets = df['Text']\n",
    "    \n",
    "    for i in range(vec_length+1):\n",
    "        weights.append([])\n",
    "    \n",
    "    for i in range(len(tweets)):\n",
    "        index += 1\n",
    "        cur_embed = []\n",
    "        cur_tweet = tweets[i]\n",
    "        cur_label = labels[i]\n",
    "        for i in cur_tweet.split():\n",
    "            if i in glove:\n",
    "                cur_embed.append(embeddings[glove[i]])\n",
    "        \n",
    "        if len(cur_embed) == 0:\n",
    "            #make sure we drop this row from the input dataframe\n",
    "            index_omit.append(index)\n",
    "            continue\n",
    "        \n",
    "        x = np.asarray(np.mean(cur_embed, axis=0))\n",
    "        \n",
    "        for j in range(vec_length):\n",
    "            weights[j].append(x[j])\n",
    "        weights[vec_length].append(0 if cur_label == 0 else 1)\n",
    "        #weights[vec_length].append(cur_label)\n",
    "        \n",
    "    df_pruned = df.drop(index_omit)\n",
    "    \n",
    "    #convert to dataframe\n",
    "    cols = {}\n",
    "    for i in range(vec_length):\n",
    "       cols['v' + str(i)] = weights[i]\n",
    "    \n",
    "    cols['class'] = weights[vec_length]\n",
    "    \n",
    "    df2 = pd.DataFrame(data=cols)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>v12</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>v15</th>\n",
       "      <th>v16</th>\n",
       "      <th>v17</th>\n",
       "      <th>...</th>\n",
       "      <th>v45</th>\n",
       "      <th>v46</th>\n",
       "      <th>v47</th>\n",
       "      <th>v48</th>\n",
       "      <th>v49</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155161</td>\n",
       "      <td>0.263687</td>\n",
       "      <td>0.043829</td>\n",
       "      <td>-0.120267</td>\n",
       "      <td>-2.900594</td>\n",
       "      <td>0.125219</td>\n",
       "      <td>0.416429</td>\n",
       "      <td>0.051185</td>\n",
       "      <td>-0.368929</td>\n",
       "      <td>0.155019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104995</td>\n",
       "      <td>0.097013</td>\n",
       "      <td>0.079060</td>\n",
       "      <td>0.138891</td>\n",
       "      <td>0.369817</td>\n",
       "      <td>0.119640</td>\n",
       "      <td>-0.093732</td>\n",
       "      <td>-0.177305</td>\n",
       "      <td>0.228087</td>\n",
       "      <td>-0.533599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.506732</td>\n",
       "      <td>0.533653</td>\n",
       "      <td>-0.239425</td>\n",
       "      <td>-0.082669</td>\n",
       "      <td>-3.877900</td>\n",
       "      <td>-0.243501</td>\n",
       "      <td>-0.267239</td>\n",
       "      <td>0.180399</td>\n",
       "      <td>0.127873</td>\n",
       "      <td>-0.032331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321023</td>\n",
       "      <td>-0.030767</td>\n",
       "      <td>-0.124344</td>\n",
       "      <td>-0.230642</td>\n",
       "      <td>0.072494</td>\n",
       "      <td>-0.093731</td>\n",
       "      <td>0.910368</td>\n",
       "      <td>-0.188011</td>\n",
       "      <td>0.156793</td>\n",
       "      <td>-0.024209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616114</td>\n",
       "      <td>0.568701</td>\n",
       "      <td>-0.146282</td>\n",
       "      <td>-0.267516</td>\n",
       "      <td>-3.095100</td>\n",
       "      <td>-0.351560</td>\n",
       "      <td>0.179257</td>\n",
       "      <td>0.152886</td>\n",
       "      <td>0.018344</td>\n",
       "      <td>0.154413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034372</td>\n",
       "      <td>0.041387</td>\n",
       "      <td>0.031561</td>\n",
       "      <td>-0.225155</td>\n",
       "      <td>0.007954</td>\n",
       "      <td>-0.314545</td>\n",
       "      <td>0.454590</td>\n",
       "      <td>-0.031889</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>-0.661508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.402962</td>\n",
       "      <td>0.203641</td>\n",
       "      <td>-0.114581</td>\n",
       "      <td>0.134512</td>\n",
       "      <td>-3.415042</td>\n",
       "      <td>-0.157732</td>\n",
       "      <td>0.020430</td>\n",
       "      <td>0.211768</td>\n",
       "      <td>0.036882</td>\n",
       "      <td>-0.172543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069752</td>\n",
       "      <td>0.245466</td>\n",
       "      <td>0.028327</td>\n",
       "      <td>-0.201005</td>\n",
       "      <td>0.133578</td>\n",
       "      <td>-0.035554</td>\n",
       "      <td>0.515226</td>\n",
       "      <td>0.211987</td>\n",
       "      <td>-0.145409</td>\n",
       "      <td>-0.181648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.530228</td>\n",
       "      <td>0.428295</td>\n",
       "      <td>0.099195</td>\n",
       "      <td>-0.344003</td>\n",
       "      <td>-3.328270</td>\n",
       "      <td>-0.014887</td>\n",
       "      <td>0.316524</td>\n",
       "      <td>0.489046</td>\n",
       "      <td>-0.030505</td>\n",
       "      <td>0.129487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053783</td>\n",
       "      <td>0.070025</td>\n",
       "      <td>0.046146</td>\n",
       "      <td>-0.097200</td>\n",
       "      <td>0.104830</td>\n",
       "      <td>-0.404194</td>\n",
       "      <td>0.540873</td>\n",
       "      <td>-0.137780</td>\n",
       "      <td>0.167950</td>\n",
       "      <td>-0.654720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v0        v1       v10       v11       v12       v13       v14  \\\n",
       "0  0.155161  0.263687  0.043829 -0.120267 -2.900594  0.125219  0.416429   \n",
       "1  0.506732  0.533653 -0.239425 -0.082669 -3.877900 -0.243501 -0.267239   \n",
       "2  0.616114  0.568701 -0.146282 -0.267516 -3.095100 -0.351560  0.179257   \n",
       "3  0.402962  0.203641 -0.114581  0.134512 -3.415042 -0.157732  0.020430   \n",
       "4  0.530228  0.428295  0.099195 -0.344003 -3.328270 -0.014887  0.316524   \n",
       "\n",
       "        v15       v16       v17  ...       v45       v46       v47       v48  \\\n",
       "0  0.051185 -0.368929  0.155019  ... -0.104995  0.097013  0.079060  0.138891   \n",
       "1  0.180399  0.127873 -0.032331  ... -0.321023 -0.030767 -0.124344 -0.230642   \n",
       "2  0.152886  0.018344  0.154413  ...  0.034372  0.041387  0.031561 -0.225155   \n",
       "3  0.211768  0.036882 -0.172543  ... -0.069752  0.245466  0.028327 -0.201005   \n",
       "4  0.489046 -0.030505  0.129487  ... -0.053783  0.070025  0.046146 -0.097200   \n",
       "\n",
       "        v49        v5        v6        v7        v8        v9  \n",
       "0  0.369817  0.119640 -0.093732 -0.177305  0.228087 -0.533599  \n",
       "1  0.072494 -0.093731  0.910368 -0.188011  0.156793 -0.024209  \n",
       "2  0.007954 -0.314545  0.454590 -0.031889  0.344140 -0.661508  \n",
       "3  0.133578 -0.035554  0.515226  0.211987 -0.145409 -0.181648  \n",
       "4  0.104830 -0.404194  0.540873 -0.137780  0.167950 -0.654720  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfv = tweets_to_df(df, relevancy, embeddings, glove)\n",
    "labels = dfv.pop('class')\n",
    "dfv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import * \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import *\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def average(x):\n",
    "    return sum(x)/len(x)\n",
    "\n",
    "def get_stats(model, X, y, cv, verbose=False):\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    auc = []\n",
    "        \n",
    "    cv_results = cross_validate(model, X, y, scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], \n",
    "                                cv=cv, return_train_score=False)\n",
    "    \n",
    "    if verbose:\n",
    "        print(cv_results)\n",
    "    \n",
    "    #now return the data\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting (0.75, 0.0306) (0.52, 0.0511) (0.63, 0.0744) (0.57, 0.0521) 0.78\n",
      "Naive Bayes (0.70, 0.0387) (0.45, 0.0449) (0.69, 0.0728) (0.54, 0.0473) 0.76\n",
      "AdaBoost (0.75, 0.0325) (0.52, 0.0756) (0.42, 0.0727) (0.46, 0.0610) 0.75\n",
      "KNN (0.75, 0.0273) (0.53, 0.0643) (0.42, 0.0777) (0.46, 0.0572) 0.72\n",
      "Perceptron (0.76, 0.0229) (0.55, 0.0530) (0.44, 0.0840) (0.48, 0.0557) 0.76\n"
     ]
    }
   ],
   "source": [
    "models = {'Perceptron': MLPClassifier(), 'KNN': KNeighborsClassifier(),\n",
    "         'AdaBoost': AdaBoostClassifier(),\n",
    "          'Naive Bayes': GaussianNB(),\n",
    "          'Voting': VotingClassifier(estimators=[('mlp', MLPClassifier()),\n",
    "                                            ('ada', AdaBoostClassifier()),\n",
    "                                            ('nb', GaussianNB())], voting='soft')}\n",
    "\n",
    "vals = []\n",
    "metric = []\n",
    "model_name = []\n",
    "\n",
    "X_new = SelectKBest(k=25).fit_transform(dfv, labels)\n",
    "\n",
    "cv = 10\n",
    "for k,v in models.items():\n",
    "    stats = get_stats(v, dfv, labels, cv)\n",
    "    accuracy_avg = np.average(stats['test_accuracy'])\n",
    "    accuracy_std = np.std(stats['test_accuracy'])\n",
    "    precision_avg = np.average(stats['test_precision'])\n",
    "    precision_std = np.std(stats['test_precision'])\n",
    "    recall_avg = np.average(stats['test_recall'])\n",
    "    recall_std = np.std(stats['test_recall'])\n",
    "    f1_avg = np.average(stats['test_f1'])\n",
    "    f1_std = np.std(stats['test_f1'])\n",
    "    auc_avg = np.average(stats['test_roc_auc'])\n",
    "    \n",
    "    print('%s (%.2f, %.4f) (%.2f, %.4f) (%.2f, %.4f) (%.2f, %.4f) %.2f' % \n",
    "          (k, accuracy_avg, accuracy_std, precision_avg, precision_std, recall_avg, \n",
    "               recall_std, f1_avg, f1_std, auc_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
