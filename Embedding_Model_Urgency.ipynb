{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ashwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ashwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ashwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora, models\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore');\n",
    "\n",
    "import process_tweet\n",
    "import importlib\n",
    "importlib.reload(process_tweet)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def normalize_df(df):\n",
    "    normed = StandardScaler().fit_transform(df)\n",
    "    return pd.DataFrame(normed, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Urgency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit stage tomorrow help hurricaneharvey relief...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bema say &lt;number&gt; pet rescue far wake harvey h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eye lone star state harvey wreck havoc heres h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want rescue dog leave behind hurricaneharvey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pm latest look radar houston heavy rain contin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Urgency\n",
       "0  hit stage tomorrow help hurricaneharvey relief...        0\n",
       "1  bema say <number> pet rescue far wake harvey h...        0\n",
       "2  eye lone star state harvey wreck havoc heres h...        0\n",
       "3       want rescue dog leave behind hurricaneharvey        0\n",
       "4  pm latest look radar houston heavy rain contin...        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('data/dataset_urgent_processed.csv')\n",
    "df2 = pd.read_csv('data/final_dataset_processed.csv')\n",
    "\n",
    "df = df[df['Urgency'] == 1]\n",
    "df2 = df2[df2['Urgency'] == 0]\n",
    "\n",
    "#now shuffle the values in non-urgent tweets\n",
    "df2 = df2.sample(frac=1.0).reset_index(drop=True)\n",
    "\n",
    "#add non-urgent tweets until urgent tweets make up 10% of the dataset\n",
    "df3 = pd.DataFrame()\n",
    "df3['Text'] = df['Text'].append(df2['Text'][:51*9], ignore_index=False)\n",
    "df3['Urgency'] = df['Urgency'].append(df2['Urgency'][:51*9], ignore_index=False)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "\n",
    "df = df3\n",
    "df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "\n",
    "print(df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# df.to_csv('data/final_urgency_dataset_unbalanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Urgency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit stage tomorrow help hurricaneharvey relief...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bema say &lt;number&gt; pet rescue far wake harvey h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eye lone star state harvey wreck havoc heres h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want rescue dog leave behind hurricaneharvey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pm latest look radar houston heavy rain contin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Urgency\n",
       "0  hit stage tomorrow help hurricaneharvey relief...        0\n",
       "1  bema say <number> pet rescue far wake harvey h...        0\n",
       "2  eye lone star state harvey wreck havoc heres h...        0\n",
       "3       want rescue dog leave behind hurricaneharvey        0\n",
       "4  pm latest look radar houston heavy rain contin...        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/final_urgency_dataset_unbalanced.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty line\n"
     ]
    }
   ],
   "source": [
    "#list of embeddings\n",
    "vec_length = 100\n",
    "embeddings = np.zeros((1193514, vec_length))\n",
    "\n",
    "#two-way map, index->word and word->index\n",
    "glove = {}\n",
    "\n",
    "index = 0\n",
    "with open('data/glove.twitter.27B/glove.twitter.27B.%dd.txt' % vec_length) as f:\n",
    "    for l in f:\n",
    "        line = []\n",
    "        try:\n",
    "            line = l.split()\n",
    "            if len(line) != vec_length+1:\n",
    "                print('empty line')\n",
    "                continue\n",
    "            \n",
    "            word = line[0]\n",
    "            embeddings[index] = np.array(line[1:]).astype(np.float)\n",
    "            glove[index] = word\n",
    "            glove[word] = index\n",
    "            index += 1\n",
    "        except:\n",
    "            print(line)\n",
    "            print(index)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sym_spell = process_tweet.create_symspell(2,7,'data/frequency_dictionary_en_82_765.txt')\n",
    "# tknzr = TweetTokenizer(strip_handles=False, reduce_len=True)\n",
    "# df['Text'] = df['Text'].map(lambda x: process_tweet.process_tweet(x, glove, tknzr, sym_spell, True))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only handles binary classification for now\n",
    "def tweets_to_df(df, labels, embeddings, glove):\n",
    "    \n",
    "    weights = []\n",
    "    index_omit = []\n",
    "    index = -1\n",
    "    tweets = df['Text']\n",
    "    \n",
    "    #a column for each entry in the embedding vector\n",
    "    for i in range(vec_length+1):\n",
    "        weights.append([])\n",
    "    \n",
    "    for i in range(len(tweets)):\n",
    "        index += 1\n",
    "        cur_embed = []\n",
    "        cur_tweet = tweets[i]\n",
    "        cur_label = labels[i]\n",
    "        for i in cur_tweet.split():\n",
    "            if i in glove:\n",
    "                cur_embed.append(embeddings[glove[i]])\n",
    "        \n",
    "        if len(cur_embed) == 0:\n",
    "            #make sure we drop this row from the input dataframe\n",
    "            index_omit.append(index)\n",
    "            continue\n",
    "        \n",
    "        x = np.asarray(np.mean(cur_embed, axis=0))\n",
    "        \n",
    "        for j in range(vec_length):\n",
    "            weights[j].append(x[j])\n",
    "        weights[vec_length].append(0 if cur_label == 0 else 1)\n",
    "        #weights[vec_length].append(cur_label)\n",
    "        \n",
    "    df_pruned = df.drop(index_omit)\n",
    "    \n",
    "    #convert to dataframe\n",
    "    cols = {}\n",
    "    for i in range(vec_length):\n",
    "       cols['v' + str(i)] = weights[i]\n",
    "    \n",
    "    cols['class'] = weights[vec_length]\n",
    "    \n",
    "    df2 = pd.DataFrame(data=cols)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v90</th>\n",
       "      <th>v91</th>\n",
       "      <th>v92</th>\n",
       "      <th>v93</th>\n",
       "      <th>v94</th>\n",
       "      <th>v95</th>\n",
       "      <th>v96</th>\n",
       "      <th>v97</th>\n",
       "      <th>v98</th>\n",
       "      <th>v99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.392471</td>\n",
       "      <td>-0.125278</td>\n",
       "      <td>-0.195383</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>-0.098483</td>\n",
       "      <td>0.508877</td>\n",
       "      <td>0.164616</td>\n",
       "      <td>-0.054078</td>\n",
       "      <td>-0.216241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058495</td>\n",
       "      <td>-0.122941</td>\n",
       "      <td>0.193241</td>\n",
       "      <td>-0.422798</td>\n",
       "      <td>0.063024</td>\n",
       "      <td>-0.227262</td>\n",
       "      <td>-0.073694</td>\n",
       "      <td>0.015016</td>\n",
       "      <td>0.148994</td>\n",
       "      <td>-0.307096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181302</td>\n",
       "      <td>0.168261</td>\n",
       "      <td>0.299544</td>\n",
       "      <td>-0.162647</td>\n",
       "      <td>-0.026963</td>\n",
       "      <td>-0.164991</td>\n",
       "      <td>0.019569</td>\n",
       "      <td>0.064372</td>\n",
       "      <td>0.113181</td>\n",
       "      <td>0.234168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042828</td>\n",
       "      <td>-0.114721</td>\n",
       "      <td>0.014692</td>\n",
       "      <td>-0.001275</td>\n",
       "      <td>0.241052</td>\n",
       "      <td>-0.073657</td>\n",
       "      <td>0.094706</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.262822</td>\n",
       "      <td>0.118727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.031068</td>\n",
       "      <td>0.480774</td>\n",
       "      <td>-0.104659</td>\n",
       "      <td>-0.022480</td>\n",
       "      <td>0.040678</td>\n",
       "      <td>-0.206603</td>\n",
       "      <td>0.095055</td>\n",
       "      <td>-0.091968</td>\n",
       "      <td>-0.067542</td>\n",
       "      <td>-0.032950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242558</td>\n",
       "      <td>-0.069266</td>\n",
       "      <td>0.019359</td>\n",
       "      <td>-0.357889</td>\n",
       "      <td>0.204037</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.118161</td>\n",
       "      <td>0.179778</td>\n",
       "      <td>0.264093</td>\n",
       "      <td>0.131799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.273855</td>\n",
       "      <td>0.084422</td>\n",
       "      <td>0.188438</td>\n",
       "      <td>-0.022144</td>\n",
       "      <td>-0.049088</td>\n",
       "      <td>-0.219914</td>\n",
       "      <td>0.624792</td>\n",
       "      <td>-0.052922</td>\n",
       "      <td>0.352596</td>\n",
       "      <td>-0.063101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023626</td>\n",
       "      <td>-0.169035</td>\n",
       "      <td>-0.110523</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>0.256314</td>\n",
       "      <td>0.399921</td>\n",
       "      <td>-0.124767</td>\n",
       "      <td>-0.008461</td>\n",
       "      <td>0.177354</td>\n",
       "      <td>0.621590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207086</td>\n",
       "      <td>0.318976</td>\n",
       "      <td>-0.069456</td>\n",
       "      <td>-0.499206</td>\n",
       "      <td>0.213039</td>\n",
       "      <td>0.048816</td>\n",
       "      <td>0.037256</td>\n",
       "      <td>0.027811</td>\n",
       "      <td>-0.007853</td>\n",
       "      <td>-0.160614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211119</td>\n",
       "      <td>-0.089914</td>\n",
       "      <td>0.251606</td>\n",
       "      <td>-0.336519</td>\n",
       "      <td>-0.167591</td>\n",
       "      <td>-0.051001</td>\n",
       "      <td>0.190905</td>\n",
       "      <td>0.268427</td>\n",
       "      <td>0.038993</td>\n",
       "      <td>-0.081418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v0        v1        v2        v3        v4        v5        v6  \\\n",
       "0  0.006767  0.392471 -0.125278 -0.195383  0.012022 -0.098483  0.508877   \n",
       "1  0.181302  0.168261  0.299544 -0.162647 -0.026963 -0.164991  0.019569   \n",
       "2  0.031068  0.480774 -0.104659 -0.022480  0.040678 -0.206603  0.095055   \n",
       "3  0.273855  0.084422  0.188438 -0.022144 -0.049088 -0.219914  0.624792   \n",
       "4  0.207086  0.318976 -0.069456 -0.499206  0.213039  0.048816  0.037256   \n",
       "\n",
       "         v7        v8        v9    ...          v90       v91       v92  \\\n",
       "0  0.164616 -0.054078 -0.216241    ...    -0.058495 -0.122941  0.193241   \n",
       "1  0.064372  0.113181  0.234168    ...    -0.042828 -0.114721  0.014692   \n",
       "2 -0.091968 -0.067542 -0.032950    ...     0.242558 -0.069266  0.019359   \n",
       "3 -0.052922  0.352596 -0.063101    ...    -0.023626 -0.169035 -0.110523   \n",
       "4  0.027811 -0.007853 -0.160614    ...    -0.211119 -0.089914  0.251606   \n",
       "\n",
       "        v93       v94       v95       v96       v97       v98       v99  \n",
       "0 -0.422798  0.063024 -0.227262 -0.073694  0.015016  0.148994 -0.307096  \n",
       "1 -0.001275  0.241052 -0.073657  0.094706  0.004472  0.262822  0.118727  \n",
       "2 -0.357889  0.204037  0.104582  0.118161  0.179778  0.264093  0.131799  \n",
       "3  0.003578  0.256314  0.399921 -0.124767 -0.008461  0.177354  0.621590  \n",
       "4 -0.336519 -0.167591 -0.051001  0.190905  0.268427  0.038993 -0.081418  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfv = tweets_to_df(df, df['Urgency'], embeddings, glove)\n",
    "labels = dfv.pop('class')\n",
    "dfv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "#this model takes in a base model and fits with resampling\n",
    "#not a general class, implementation is specific to the above dataset\n",
    "class ResamplingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        #first resample to balance the dataset, assuming dataframe input\n",
    "        X = X.copy()\n",
    "        X['class'] = y\n",
    "        \n",
    "        df_urgent = X[X['class'] == 1]\n",
    "        df_not_urgent = X[X['class'] == 0]\n",
    "        df_samples = df_urgent.sample(df_not_urgent.shape[0] - df_urgent.shape[0], replace=True)\n",
    "        df = pd.concat([df_not_urgent, df_samples])\n",
    "        df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "        y = df.pop('class')\n",
    "        \n",
    "        self.model = self.model.fit(df, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        return self.model.decision_function(X)\n",
    "    \n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        return self.model.score(X, y, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import * \n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def average(x):\n",
    "    return sum(x)/len(x)\n",
    "\n",
    "#same as for relevancy, but added resampling\n",
    "def get_stats(model, X, y, cv, verbose=False):\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    auc = []\n",
    "        \n",
    "    cv_results = cross_validate(SMOTEClassifier(model), X, y, scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], \n",
    "                                cv=cv, return_train_score=False)\n",
    "    \n",
    "    if verbose:\n",
    "        print(cv_results)\n",
    "    \n",
    "    #now return the data\n",
    "    return cv_results\n",
    "\n",
    "def print_stats(models, method, dfv, labels):\n",
    "    \n",
    "    vals = []\n",
    "    metric = []\n",
    "    model_name = []\n",
    "\n",
    "    f1 = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    accuracy = []\n",
    "    auc = []\n",
    "\n",
    "    cv = 3\n",
    "    for k,v in models.items():\n",
    "        stats = get_stats(v, dfv, labels, cv)\n",
    "        accuracy_avg = np.average(stats['test_accuracy'])\n",
    "        accuracy_std = np.std(stats['test_accuracy'])\n",
    "        precision_avg = np.average(stats['test_precision'])\n",
    "        precision_std = np.std(stats['test_precision'])\n",
    "        recall_avg = np.average(stats['test_recall'])\n",
    "        recall_std = np.std(stats['test_recall'])\n",
    "        f1_avg = np.average(stats['test_f1'])\n",
    "        f1_std = np.std(stats['test_f1'])\n",
    "        auc_avg = np.average(stats['test_roc_auc'])\n",
    "\n",
    "        f1.append('%.2f ± %.2f' % (f1_avg, f1_std))\n",
    "        precision.append('%.2f ± %.2f' % (precision_avg, precision_std))\n",
    "        recall.append('%.2f ± %.2f' % (recall_avg, recall_std))\n",
    "        accuracy.append('%.2f ± %.2f' % (accuracy_avg, accuracy_std))\n",
    "        auc.append('%.2f' % auc_avg)\n",
    "\n",
    "    df_view = pd.DataFrame(data={'Method': method, 'f1': f1, \n",
    "                                 'precision':precision, 'recall':recall,\n",
    "                                 'accuracy':accuracy, 'auc':auc})\n",
    "    display(df_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.41 ± 0.04</td>\n",
       "      <td>0.32 ± 0.01</td>\n",
       "      <td>0.59 ± 0.14</td>\n",
       "      <td>0.84 ± 0.02</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.43 ± 0.06</td>\n",
       "      <td>0.37 ± 0.04</td>\n",
       "      <td>0.51 ± 0.10</td>\n",
       "      <td>0.86 ± 0.01</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.38 ± 0.08</td>\n",
       "      <td>0.38 ± 0.05</td>\n",
       "      <td>0.41 ± 0.13</td>\n",
       "      <td>0.87 ± 0.02</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.24 ± 0.03</td>\n",
       "      <td>0.28 ± 0.06</td>\n",
       "      <td>0.22 ± 0.03</td>\n",
       "      <td>0.86 ± 0.02</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.43 ± 0.07</td>\n",
       "      <td>0.34 ± 0.07</td>\n",
       "      <td>0.65 ± 0.14</td>\n",
       "      <td>0.83 ± 0.05</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.41 ± 0.04  0.32 ± 0.01  0.59 ± 0.14  0.84 ± 0.02   \n",
       "1                  Voting  0.43 ± 0.06  0.37 ± 0.04  0.51 ± 0.10  0.86 ± 0.01   \n",
       "2                     MLP  0.38 ± 0.08  0.38 ± 0.05  0.41 ± 0.13  0.87 ± 0.02   \n",
       "3                AdaBoost  0.24 ± 0.03  0.28 ± 0.06  0.22 ± 0.03  0.86 ± 0.02   \n",
       "4  Support Vector Machine  0.43 ± 0.07  0.34 ± 0.07  0.65 ± 0.14  0.83 ± 0.05   \n",
       "\n",
       "    auc  \n",
       "0  0.77  \n",
       "1  0.79  \n",
       "2  0.78  \n",
       "3  0.72  \n",
       "4  0.82  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Voting': VotingClassifier(estimators=[('mlp', MLPClassifier()),\n",
    "                                    ('ada', AdaBoostClassifier()),\n",
    "                                    ('nb', GaussianNB())], voting='soft'),\n",
    "          'Perceptron': MLPClassifier(),\n",
    "          'AdaBoost': AdaBoostClassifier(),\n",
    "          'Support Vector Machine': SVC()\n",
    "        }\n",
    "\n",
    "method = ['Naive Bayes', 'Voting', 'MLP', 'AdaBoost', 'Support Vector Machine']\n",
    "print_stats(models, method, dfv, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try using randomized logistic regression to extract the most useful features from the 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try a different approach, recursive feature elimination, and compare the selected features to those selected with randomized logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.43 ± 0.04</td>\n",
       "      <td>0.32 ± 0.03</td>\n",
       "      <td>0.69 ± 0.07</td>\n",
       "      <td>0.82 ± 0.01</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.48 ± 0.07</td>\n",
       "      <td>0.40 ± 0.05</td>\n",
       "      <td>0.61 ± 0.12</td>\n",
       "      <td>0.87 ± 0.01</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.43 ± 0.04</td>\n",
       "      <td>0.38 ± 0.05</td>\n",
       "      <td>0.51 ± 0.07</td>\n",
       "      <td>0.86 ± 0.02</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.35 ± 0.04</td>\n",
       "      <td>0.35 ± 0.03</td>\n",
       "      <td>0.35 ± 0.05</td>\n",
       "      <td>0.87 ± 0.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.42 ± 0.04</td>\n",
       "      <td>0.30 ± 0.05</td>\n",
       "      <td>0.75 ± 0.06</td>\n",
       "      <td>0.79 ± 0.05</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.43 ± 0.04  0.32 ± 0.03  0.69 ± 0.07  0.82 ± 0.01   \n",
       "1                  Voting  0.48 ± 0.07  0.40 ± 0.05  0.61 ± 0.12  0.87 ± 0.01   \n",
       "2                     MLP  0.43 ± 0.04  0.38 ± 0.05  0.51 ± 0.07  0.86 ± 0.02   \n",
       "3                AdaBoost  0.35 ± 0.04  0.35 ± 0.03  0.35 ± 0.05  0.87 ± 0.00   \n",
       "4  Support Vector Machine  0.42 ± 0.04  0.30 ± 0.05  0.75 ± 0.06  0.79 ± 0.05   \n",
       "\n",
       "    auc  \n",
       "0  0.82  \n",
       "1  0.82  \n",
       "2  0.83  \n",
       "3  0.75  \n",
       "4  0.85  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.38 ± 0.02</td>\n",
       "      <td>0.28 ± 0.01</td>\n",
       "      <td>0.61 ± 0.10</td>\n",
       "      <td>0.80 ± 0.02</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.48 ± 0.09</td>\n",
       "      <td>0.44 ± 0.12</td>\n",
       "      <td>0.59 ± 0.17</td>\n",
       "      <td>0.87 ± 0.03</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.43 ± 0.05</td>\n",
       "      <td>0.41 ± 0.04</td>\n",
       "      <td>0.47 ± 0.08</td>\n",
       "      <td>0.88 ± 0.01</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.33 ± 0.05</td>\n",
       "      <td>0.35 ± 0.03</td>\n",
       "      <td>0.31 ± 0.07</td>\n",
       "      <td>0.87 ± 0.01</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.43 ± 0.04</td>\n",
       "      <td>0.31 ± 0.03</td>\n",
       "      <td>0.69 ± 0.10</td>\n",
       "      <td>0.82 ± 0.02</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.38 ± 0.02  0.28 ± 0.01  0.61 ± 0.10  0.80 ± 0.02   \n",
       "1                  Voting  0.48 ± 0.09  0.44 ± 0.12  0.59 ± 0.17  0.87 ± 0.03   \n",
       "2                     MLP  0.43 ± 0.05  0.41 ± 0.04  0.47 ± 0.08  0.88 ± 0.01   \n",
       "3                AdaBoost  0.33 ± 0.05  0.35 ± 0.03  0.31 ± 0.07  0.87 ± 0.01   \n",
       "4  Support Vector Machine  0.43 ± 0.04  0.31 ± 0.03  0.69 ± 0.10  0.82 ± 0.02   \n",
       "\n",
       "    auc  \n",
       "0  0.78  \n",
       "1  0.84  \n",
       "2  0.86  \n",
       "3  0.72  \n",
       "4  0.85  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Voting': VotingClassifier(estimators=[('mlp', MLPClassifier()),\n",
    "                                            ('ada', AdaBoostClassifier()),\n",
    "                                            ('nb', GaussianNB())], voting='soft'),\n",
    "          'Perceptron': MLPClassifier(),\n",
    "          'AdaBoost': AdaBoostClassifier(),\n",
    "          'Support Vector Machine': SVC()\n",
    "        }\n",
    "method = ['Naive Bayes', 'Voting', 'MLP', 'AdaBoost', 'Support Vector Machine']\n",
    "models2 = [('Logistic Regression', LogisticRegression()), ('LinearSVC', LinearSVC())]\n",
    "\n",
    "for name, model in models2:\n",
    "    rfecv = RFECV(model, step=1, scoring='f1', cv=10)\n",
    "    rfecv = rfecv.fit(dfv, labels)\n",
    "    mask = rfecv.support_\n",
    "    \n",
    "    drop_features = []\n",
    "    index = 0\n",
    "    for val in mask:\n",
    "        if not val:\n",
    "            drop_features.append('v'+str(index))\n",
    "        index += 1\n",
    "    \n",
    "    df_rfecv = dfv.drop(drop_features, axis=1)\n",
    "    print(name + ':')\n",
    "    print_stats(models, method, df_rfecv, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.31 ± 0.06</td>\n",
       "      <td>0.22 ± 0.03</td>\n",
       "      <td>0.55 ± 0.19</td>\n",
       "      <td>0.77 ± 0.02</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.35 ± 0.03</td>\n",
       "      <td>0.26 ± 0.01</td>\n",
       "      <td>0.57 ± 0.14</td>\n",
       "      <td>0.79 ± 0.02</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.37 ± 0.04</td>\n",
       "      <td>0.27 ± 0.01</td>\n",
       "      <td>0.61 ± 0.15</td>\n",
       "      <td>0.79 ± 0.02</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.27 ± 0.02</td>\n",
       "      <td>0.26 ± 0.02</td>\n",
       "      <td>0.27 ± 0.03</td>\n",
       "      <td>0.85 ± 0.01</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.37 ± 0.05</td>\n",
       "      <td>0.28 ± 0.03</td>\n",
       "      <td>0.57 ± 0.10</td>\n",
       "      <td>0.81 ± 0.01</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.31 ± 0.06  0.22 ± 0.03  0.55 ± 0.19  0.77 ± 0.02   \n",
       "1                  Voting  0.35 ± 0.03  0.26 ± 0.01  0.57 ± 0.14  0.79 ± 0.02   \n",
       "2                     MLP  0.37 ± 0.04  0.27 ± 0.01  0.61 ± 0.15  0.79 ± 0.02   \n",
       "3                AdaBoost  0.27 ± 0.02  0.26 ± 0.02  0.27 ± 0.03  0.85 ± 0.01   \n",
       "4  Support Vector Machine  0.37 ± 0.05  0.28 ± 0.03  0.57 ± 0.10  0.81 ± 0.01   \n",
       "\n",
       "    auc  \n",
       "0  0.77  \n",
       "1  0.78  \n",
       "2  0.78  \n",
       "3  0.60  \n",
       "4  0.77  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models3 = [('Decision Tree', DecisionTreeClassifier())]\n",
    "\n",
    "for name, model in models3:\n",
    "    rfecv = RFECV(model, step=1, scoring='f1', cv=10)\n",
    "    rfecv = rfecv.fit(dfv, labels)\n",
    "    mask = rfecv.support_\n",
    "    \n",
    "    drop_features = []\n",
    "    index = 0\n",
    "    for val in mask:\n",
    "        if not val:\n",
    "            drop_features.append('v'+str(index))\n",
    "        index += 1\n",
    "    \n",
    "    df_rfecv = dfv.drop(drop_features, axis=1)\n",
    "    print(name + ':')\n",
    "    print_stats(models, method, df_rfecv, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have gone through various feature selection methods, we conclude that RFECV with logistic regression is the best subset selection method. Our next step is to remove variables that are strongly correlated with each other (if any exist) to further prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#rescale the data\n",
    "data = dfv.values\n",
    "scaler = MinMaxScaler(feature_range=[0, 1])\n",
    "data_rescaled = scaler.fit_transform(data)\n",
    "\n",
    "pca = PCA().fit(data_rescaled)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above calculation says that we should keep about 70 of the 100 principal components to capture over 90% of the variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.42 ± 0.06</td>\n",
       "      <td>0.31 ± 0.05</td>\n",
       "      <td>0.63 ± 0.07</td>\n",
       "      <td>0.82 ± 0.03</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.50 ± 0.05</td>\n",
       "      <td>0.43 ± 0.02</td>\n",
       "      <td>0.61 ± 0.10</td>\n",
       "      <td>0.88 ± 0.00</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.48 ± 0.04</td>\n",
       "      <td>0.40 ± 0.04</td>\n",
       "      <td>0.61 ± 0.07</td>\n",
       "      <td>0.87 ± 0.01</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.40 ± 0.09</td>\n",
       "      <td>0.37 ± 0.05</td>\n",
       "      <td>0.45 ± 0.15</td>\n",
       "      <td>0.87 ± 0.01</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.41 ± 0.06</td>\n",
       "      <td>0.30 ± 0.05</td>\n",
       "      <td>0.69 ± 0.07</td>\n",
       "      <td>0.80 ± 0.03</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.42 ± 0.06  0.31 ± 0.05  0.63 ± 0.07  0.82 ± 0.03   \n",
       "1                  Voting  0.50 ± 0.05  0.43 ± 0.02  0.61 ± 0.10  0.88 ± 0.00   \n",
       "2                     MLP  0.48 ± 0.04  0.40 ± 0.04  0.61 ± 0.07  0.87 ± 0.01   \n",
       "3                AdaBoost  0.40 ± 0.09  0.37 ± 0.05  0.45 ± 0.15  0.87 ± 0.01   \n",
       "4  Support Vector Machine  0.41 ± 0.06  0.30 ± 0.05  0.69 ± 0.07  0.80 ± 0.03   \n",
       "\n",
       "    auc  \n",
       "0  0.82  \n",
       "1  0.83  \n",
       "2  0.85  \n",
       "3  0.74  \n",
       "4  0.85  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#now test the models using this projected dataset\n",
    "pca = PCA(n_components=60)\n",
    "data_pca = pca.fit_transform(data_rescaled)\n",
    "df_pca = pd.DataFrame(data_pca)\n",
    "\n",
    "rfecv = RFECV(LogisticRegression(), step=1, scoring='f1', cv=10)\n",
    "rfecv = rfecv.fit(df_pca, labels)\n",
    "mask = rfecv.support_\n",
    "\n",
    "drop_features = []\n",
    "index = 0\n",
    "for val in mask:\n",
    "    if not val:\n",
    "        drop_features.append(index)\n",
    "    index += 1\n",
    "\n",
    "df_pca = df_pca.drop(drop_features, axis=1)\n",
    "print_stats(models, method, df_pca, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.31 ± 0.09</td>\n",
       "      <td>0.22 ± 0.06</td>\n",
       "      <td>0.53 ± 0.17</td>\n",
       "      <td>0.77 ± 0.03</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.34 ± 0.03</td>\n",
       "      <td>0.31 ± 0.04</td>\n",
       "      <td>0.39 ± 0.03</td>\n",
       "      <td>0.85 ± 0.01</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.44 ± 0.00</td>\n",
       "      <td>0.40 ± 0.02</td>\n",
       "      <td>0.49 ± 0.03</td>\n",
       "      <td>0.87 ± 0.01</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.28 ± 0.05</td>\n",
       "      <td>0.24 ± 0.03</td>\n",
       "      <td>0.33 ± 0.10</td>\n",
       "      <td>0.83 ± 0.01</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.41 ± 0.05</td>\n",
       "      <td>0.30 ± 0.05</td>\n",
       "      <td>0.69 ± 0.07</td>\n",
       "      <td>0.80 ± 0.05</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.31 ± 0.09  0.22 ± 0.06  0.53 ± 0.17  0.77 ± 0.03   \n",
       "1                  Voting  0.34 ± 0.03  0.31 ± 0.04  0.39 ± 0.03  0.85 ± 0.01   \n",
       "2                     MLP  0.44 ± 0.00  0.40 ± 0.02  0.49 ± 0.03  0.87 ± 0.01   \n",
       "3                AdaBoost  0.28 ± 0.05  0.24 ± 0.03  0.33 ± 0.10  0.83 ± 0.01   \n",
       "4  Support Vector Machine  0.41 ± 0.05  0.30 ± 0.05  0.69 ± 0.07  0.80 ± 0.05   \n",
       "\n",
       "    auc  \n",
       "0  0.72  \n",
       "1  0.79  \n",
       "2  0.81  \n",
       "3  0.67  \n",
       "4  0.84  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#now test the models using this projected dataset\n",
    "pca = PCA(n_components=40)\n",
    "data_pca = pca.fit_transform(data_rescaled)\n",
    "df_pca = pd.DataFrame(data_pca)\n",
    "\n",
    "rfecv = RFECV(LogisticRegression(), scoring='f1', step=1, cv=10)\n",
    "rfecv = rfecv.fit(df_pca, labels)\n",
    "mask = rfecv.support_\n",
    "\n",
    "drop_features = []\n",
    "index = 0\n",
    "for val in mask:\n",
    "    if not val:\n",
    "        drop_features.append(index)\n",
    "    index += 1\n",
    "\n",
    "df_pca = df_pca.drop(drop_features, axis=1)\n",
    "print_stats(models, method, df_pca, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.36 ± 0.02</td>\n",
       "      <td>0.24 ± 0.01</td>\n",
       "      <td>0.69 ± 0.10</td>\n",
       "      <td>0.76 ± 0.02</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.35 ± 0.02</td>\n",
       "      <td>0.24 ± 0.02</td>\n",
       "      <td>0.63 ± 0.10</td>\n",
       "      <td>0.77 ± 0.03</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.34 ± 0.05</td>\n",
       "      <td>0.24 ± 0.04</td>\n",
       "      <td>0.63 ± 0.15</td>\n",
       "      <td>0.76 ± 0.04</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.28 ± 0.05</td>\n",
       "      <td>0.23 ± 0.02</td>\n",
       "      <td>0.37 ± 0.11</td>\n",
       "      <td>0.82 ± 0.01</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.37 ± 0.05</td>\n",
       "      <td>0.26 ± 0.05</td>\n",
       "      <td>0.71 ± 0.10</td>\n",
       "      <td>0.76 ± 0.05</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.36 ± 0.02  0.24 ± 0.01  0.69 ± 0.10  0.76 ± 0.02   \n",
       "1                  Voting  0.35 ± 0.02  0.24 ± 0.02  0.63 ± 0.10  0.77 ± 0.03   \n",
       "2                     MLP  0.34 ± 0.05  0.24 ± 0.04  0.63 ± 0.15  0.76 ± 0.04   \n",
       "3                AdaBoost  0.28 ± 0.05  0.23 ± 0.02  0.37 ± 0.11  0.82 ± 0.01   \n",
       "4  Support Vector Machine  0.37 ± 0.05  0.26 ± 0.05  0.71 ± 0.10  0.76 ± 0.05   \n",
       "\n",
       "    auc  \n",
       "0  0.80  \n",
       "1  0.79  \n",
       "2  0.80  \n",
       "3  0.72  \n",
       "4  0.81  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#now test the models using this projected dataset\n",
    "pca = PCA(n_components=20)\n",
    "data_pca = pca.fit_transform(data_rescaled)\n",
    "df_pca = pd.DataFrame(data_pca)\n",
    "\n",
    "rfecv = RFECV(LogisticRegression(), scoring='f1', step=1, cv=10)\n",
    "rfecv = rfecv.fit(df_pca, labels)\n",
    "mask = rfecv.support_\n",
    "\n",
    "drop_features = []\n",
    "index = 0\n",
    "for val in mask:\n",
    "    if not val:\n",
    "        drop_features.append(index)\n",
    "    index += 1\n",
    "\n",
    "df_pca = df_pca.drop(drop_features, axis=1)\n",
    "print_stats(models, method, df_pca, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.39 ± 0.03</td>\n",
       "      <td>0.29 ± 0.03</td>\n",
       "      <td>0.63 ± 0.06</td>\n",
       "      <td>0.81 ± 0.02</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.46 ± 0.03</td>\n",
       "      <td>0.39 ± 0.06</td>\n",
       "      <td>0.57 ± 0.06</td>\n",
       "      <td>0.86 ± 0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.50 ± 0.01</td>\n",
       "      <td>0.47 ± 0.05</td>\n",
       "      <td>0.57 ± 0.10</td>\n",
       "      <td>0.89 ± 0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.33 ± 0.07</td>\n",
       "      <td>0.28 ± 0.02</td>\n",
       "      <td>0.43 ± 0.17</td>\n",
       "      <td>0.84 ± 0.01</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.40 ± 0.05</td>\n",
       "      <td>0.30 ± 0.05</td>\n",
       "      <td>0.61 ± 0.06</td>\n",
       "      <td>0.82 ± 0.03</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.39 ± 0.03  0.29 ± 0.03  0.63 ± 0.06  0.81 ± 0.02   \n",
       "1                  Voting  0.46 ± 0.03  0.39 ± 0.06  0.57 ± 0.06  0.86 ± 0.02   \n",
       "2                     MLP  0.50 ± 0.01  0.47 ± 0.05  0.57 ± 0.10  0.89 ± 0.02   \n",
       "3                AdaBoost  0.33 ± 0.07  0.28 ± 0.02  0.43 ± 0.17  0.84 ± 0.01   \n",
       "4  Support Vector Machine  0.40 ± 0.05  0.30 ± 0.05  0.61 ± 0.06  0.82 ± 0.03   \n",
       "\n",
       "    auc  \n",
       "0  0.82  \n",
       "1  0.84  \n",
       "2  0.84  \n",
       "3  0.75  \n",
       "4  0.82  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = dfv.values\n",
    "scaler = MinMaxScaler(feature_range=[0, 1])\n",
    "data_rescaled = scaler.fit_transform(data)\n",
    "\n",
    "pca = PCA(n_components=60)\n",
    "data_pca = pca.fit_transform(data_rescaled)\n",
    "df_pca = pd.DataFrame(data_pca)\n",
    "\n",
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Voting': VotingClassifier(estimators=[('mlp', MLPClassifier(alpha=0.001)),\n",
    "                                            ('ada', AdaBoostClassifier(n_estimators=100, learning_rate=0.25)),\n",
    "                                            ('SVC', SVC(C=10, gamma=1, kernel='linear', \n",
    "                                                        probability=True)),\n",
    "                                            ('nb', GaussianNB())], voting='soft'),\n",
    "          'Perceptron': MLPClassifier(alpha=0.001),\n",
    "          'AdaBoost': AdaBoostClassifier(n_estimators=100, learning_rate=0.25),\n",
    "          'Support Vector Machine': SVC(C=10, degree=3, gamma=1, kernel='linear', class_weight=None)}\n",
    "\n",
    "method = ['Naive Bayes', 'Voting', 'MLP', 'AdaBoost', 'Support Vector Machine']\n",
    "\n",
    "#now test the models using this projected dataset\n",
    "rfecv = RFECV(LogisticRegression(), step=1, scoring='f1', cv=10)\n",
    "rfecv = rfecv.fit(df_pca, labels)\n",
    "mask = rfecv.support_\n",
    "\n",
    "drop_features = []\n",
    "index = 0\n",
    "for val in mask:\n",
    "    if not val:\n",
    "        drop_features.append(index)\n",
    "    index += 1\n",
    "\n",
    "df_pca = df_pca.drop(drop_features, axis=1)\n",
    "print_stats(models, method, df_pca, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__activation': 'relu',\n",
       " 'model__alpha': 0.001,\n",
       " 'model__early_stopping': False,\n",
       " 'model__solver': 'adam'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#start with MLP\n",
    "mlp_cv = GridSearchCV(ResamplingClassifier(MLPClassifier()), param_grid={\n",
    "        'model__activation': ('logistic', 'tanh', 'relu'),\n",
    "        'model__solver': ('lbfgs', 'adam'),\n",
    "        'model__alpha': (0.0001, 0.001, 0.01, 0.1),\n",
    "        'model__early_stopping': (True, False)}, scoring='f1', cv=10)\n",
    "\n",
    "mlp_cv.fit(df_pca, labels)\n",
    "mlp_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__C': 10,\n",
       " 'model__class_weight': None,\n",
       " 'model__degree': 3,\n",
       " 'model__gamma': 1,\n",
       " 'model__kernel': 'linear'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now try SVM\n",
    "svm_cv = GridSearchCV(ResamplingClassifier(SVC()), param_grid={\n",
    "        'model__kernel': ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "        'model__degree': (2,3),\n",
    "        'model__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'model__gamma': [0.001, 0.01, 0.1, 1],\n",
    "        'model__class_weight': (None, 'balanced')}, scoring='f1', cv=10)\n",
    "\n",
    "svm_cv.fit(df_pca, labels)\n",
    "svm_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__base_estimator': None,\n",
       " 'model__learning_rate': 0.25,\n",
       " 'model__n_estimators': 100}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now try AdaBoost\n",
    "ada_cv = GridSearchCV(ResamplingClassifier(AdaBoostClassifier()), param_grid={\n",
    "        'model__base_estimator': (None, DecisionTreeClassifier(max_depth=2), DecisionTreeClassifier(max_depth=3)),\n",
    "        'model__n_estimators': (5 0,100, 200),\n",
    "        'model__learning_rate': (0.25, 0.5, 1)}, scoring='f1', cv=10)\n",
    "\n",
    "ada_cv.fit(df_pca, labels)\n",
    "ada_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__learning_rate': 0.25}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fine-tuning AdaBoost further\n",
    "ada_cv2 = GridSearchCV(ResamplingClassifier(AdaBoostClassifier(n_estimators=100)), param_grid={\n",
    "        'model__learning_rate': (0.05, 0.1, 0.25)}, scoring='f1', cv=10)\n",
    "\n",
    "ada_cv2.fit(df_pca, labels)\n",
    "ada_cv2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P. (2002). SMOTE: synthetic minority over-sampling technique. Journal of artificial intelligence research, 16, 321-357."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from imblearn.over_sampling import *\n",
    "\n",
    "#this model takes in a base model and fits after SMOTE resampling\n",
    "#not a general class, implementation is specific to the above dataset\n",
    "class SMOTEClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        #first resample to balance the dataset, assuming dataframe input\n",
    "        X_res, y_res = SVMSMOTE().fit_resample(X, y)\n",
    "        self.model = self.model.fit(X_res, y_res)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        return self.model.decision_function(X)\n",
    "    \n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        return self.model.score(X, y, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.41 ± 0.13</td>\n",
       "      <td>0.48 ± 0.17</td>\n",
       "      <td>0.37 ± 0.11</td>\n",
       "      <td>0.89 ± 0.04</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.40 ± 0.12</td>\n",
       "      <td>0.41 ± 0.10</td>\n",
       "      <td>0.39 ± 0.15</td>\n",
       "      <td>0.88 ± 0.02</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.35 ± 0.01</td>\n",
       "      <td>0.38 ± 0.06</td>\n",
       "      <td>0.35 ± 0.08</td>\n",
       "      <td>0.87 ± 0.03</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.24 ± 0.07</td>\n",
       "      <td>0.24 ± 0.07</td>\n",
       "      <td>0.24 ± 0.08</td>\n",
       "      <td>0.85 ± 0.01</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.37 ± 0.07</td>\n",
       "      <td>0.34 ± 0.04</td>\n",
       "      <td>0.43 ± 0.15</td>\n",
       "      <td>0.86 ± 0.02</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.41 ± 0.13  0.48 ± 0.17  0.37 ± 0.11  0.89 ± 0.04   \n",
       "1                  Voting  0.40 ± 0.12  0.41 ± 0.10  0.39 ± 0.15  0.88 ± 0.02   \n",
       "2                     MLP  0.35 ± 0.01  0.38 ± 0.06  0.35 ± 0.08  0.87 ± 0.03   \n",
       "3                AdaBoost  0.24 ± 0.07  0.24 ± 0.07  0.24 ± 0.08  0.85 ± 0.01   \n",
       "4  Support Vector Machine  0.37 ± 0.07  0.34 ± 0.04  0.43 ± 0.15  0.86 ± 0.02   \n",
       "\n",
       "    auc  \n",
       "0  0.70  \n",
       "1  0.76  \n",
       "2  0.77  \n",
       "3  0.67  \n",
       "4  0.80  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Voting': VotingClassifier(estimators=[('mlp', MLPClassifier()),\n",
    "                                    ('ada', AdaBoostClassifier()),\n",
    "                                    ('nb', GaussianNB())], voting='soft'),\n",
    "          'Perceptron': MLPClassifier(),\n",
    "          'AdaBoost': AdaBoostClassifier(),\n",
    "          'Support Vector Machine': SVC()\n",
    "        }\n",
    "\n",
    "method = ['Naive Bayes', 'Voting', 'MLP', 'AdaBoost', 'Support Vector Machine']\n",
    "print_stats(models, method, dfv, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try a different approach, recursive feature elimination, and compare the selected features to those selected with randomized logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.39 ± 0.06</td>\n",
       "      <td>0.58 ± 0.31</td>\n",
       "      <td>0.37 ± 0.10</td>\n",
       "      <td>0.88 ± 0.04</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.42 ± 0.09</td>\n",
       "      <td>0.62 ± 0.29</td>\n",
       "      <td>0.39 ± 0.12</td>\n",
       "      <td>0.89 ± 0.04</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.44 ± 0.03</td>\n",
       "      <td>0.45 ± 0.10</td>\n",
       "      <td>0.45 ± 0.03</td>\n",
       "      <td>0.88 ± 0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.35 ± 0.06</td>\n",
       "      <td>0.31 ± 0.07</td>\n",
       "      <td>0.41 ± 0.05</td>\n",
       "      <td>0.85 ± 0.03</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.45 ± 0.05</td>\n",
       "      <td>0.39 ± 0.05</td>\n",
       "      <td>0.55 ± 0.03</td>\n",
       "      <td>0.87 ± 0.02</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.39 ± 0.06  0.58 ± 0.31  0.37 ± 0.10  0.88 ± 0.04   \n",
       "1                  Voting  0.42 ± 0.09  0.62 ± 0.29  0.39 ± 0.12  0.89 ± 0.04   \n",
       "2                     MLP  0.44 ± 0.03  0.45 ± 0.10  0.45 ± 0.03  0.88 ± 0.02   \n",
       "3                AdaBoost  0.35 ± 0.06  0.31 ± 0.07  0.41 ± 0.05  0.85 ± 0.03   \n",
       "4  Support Vector Machine  0.45 ± 0.05  0.39 ± 0.05  0.55 ± 0.03  0.87 ± 0.02   \n",
       "\n",
       "    auc  \n",
       "0  0.75  \n",
       "1  0.82  \n",
       "2  0.84  \n",
       "3  0.74  \n",
       "4  0.82  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.31 ± 0.08</td>\n",
       "      <td>0.40 ± 0.18</td>\n",
       "      <td>0.27 ± 0.03</td>\n",
       "      <td>0.87 ± 0.04</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.36 ± 0.07</td>\n",
       "      <td>0.54 ± 0.19</td>\n",
       "      <td>0.27 ± 0.03</td>\n",
       "      <td>0.90 ± 0.03</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.45 ± 0.02</td>\n",
       "      <td>0.41 ± 0.04</td>\n",
       "      <td>0.51 ± 0.06</td>\n",
       "      <td>0.87 ± 0.01</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.28 ± 0.07</td>\n",
       "      <td>0.29 ± 0.10</td>\n",
       "      <td>0.27 ± 0.07</td>\n",
       "      <td>0.85 ± 0.02</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.44 ± 0.06</td>\n",
       "      <td>0.37 ± 0.06</td>\n",
       "      <td>0.55 ± 0.07</td>\n",
       "      <td>0.86 ± 0.02</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.31 ± 0.08  0.40 ± 0.18  0.27 ± 0.03  0.87 ± 0.04   \n",
       "1                  Voting  0.36 ± 0.07  0.54 ± 0.19  0.27 ± 0.03  0.90 ± 0.03   \n",
       "2                     MLP  0.45 ± 0.02  0.41 ± 0.04  0.51 ± 0.06  0.87 ± 0.01   \n",
       "3                AdaBoost  0.28 ± 0.07  0.29 ± 0.10  0.27 ± 0.07  0.85 ± 0.02   \n",
       "4  Support Vector Machine  0.44 ± 0.06  0.37 ± 0.06  0.55 ± 0.07  0.86 ± 0.02   \n",
       "\n",
       "    auc  \n",
       "0  0.74  \n",
       "1  0.82  \n",
       "2  0.87  \n",
       "3  0.72  \n",
       "4  0.83  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Voting': VotingClassifier(estimators=[('mlp', MLPClassifier()),\n",
    "                                            ('ada', AdaBoostClassifier()),\n",
    "                                            ('nb', GaussianNB())], voting='soft'),\n",
    "          'Perceptron': MLPClassifier(),\n",
    "          'AdaBoost': AdaBoostClassifier(),\n",
    "          'Support Vector Machine': SVC()\n",
    "        }\n",
    "method = ['Naive Bayes', 'Voting', 'MLP', 'AdaBoost', 'Support Vector Machine']\n",
    "models2 = [('Logistic Regression', LogisticRegression()), ('LinearSVC', LinearSVC())]\n",
    "\n",
    "for name, model in models2:\n",
    "    rfecv = RFECV(model, step=1, scoring='f1', cv=10)\n",
    "    rfecv = rfecv.fit(dfv, labels)\n",
    "    mask = rfecv.support_\n",
    "    \n",
    "    drop_features = []\n",
    "    index = 0\n",
    "    for val in mask:\n",
    "        if not val:\n",
    "            drop_features.append('v'+str(index))\n",
    "        index += 1\n",
    "    \n",
    "    df_rfecv = dfv.drop(drop_features, axis=1)\n",
    "    print(name + ':')\n",
    "    print_stats(models, method, df_rfecv, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#rescale the data\n",
    "data = dfv.values\n",
    "scaler = MinMaxScaler(feature_range=[0, 1])\n",
    "data_rescaled = scaler.fit_transform(data)\n",
    "\n",
    "pca = PCA().fit(data_rescaled)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above calculation says that we should keep about 70 of the 100 principal components to capture over 90% of the variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.40 ± 0.05</td>\n",
       "      <td>0.40 ± 0.07</td>\n",
       "      <td>0.47 ± 0.17</td>\n",
       "      <td>0.86 ± 0.03</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.46 ± 0.07</td>\n",
       "      <td>0.45 ± 0.15</td>\n",
       "      <td>0.51 ± 0.06</td>\n",
       "      <td>0.88 ± 0.03</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.54 ± 0.04</td>\n",
       "      <td>0.48 ± 0.06</td>\n",
       "      <td>0.63 ± 0.03</td>\n",
       "      <td>0.89 ± 0.01</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.43 ± 0.03</td>\n",
       "      <td>0.39 ± 0.02</td>\n",
       "      <td>0.49 ± 0.07</td>\n",
       "      <td>0.87 ± 0.01</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.42 ± 0.03</td>\n",
       "      <td>0.33 ± 0.06</td>\n",
       "      <td>0.61 ± 0.06</td>\n",
       "      <td>0.83 ± 0.04</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.40 ± 0.05  0.40 ± 0.07  0.47 ± 0.17  0.86 ± 0.03   \n",
       "1                  Voting  0.46 ± 0.07  0.45 ± 0.15  0.51 ± 0.06  0.88 ± 0.03   \n",
       "2                     MLP  0.54 ± 0.04  0.48 ± 0.06  0.63 ± 0.03  0.89 ± 0.01   \n",
       "3                AdaBoost  0.43 ± 0.03  0.39 ± 0.02  0.49 ± 0.07  0.87 ± 0.01   \n",
       "4  Support Vector Machine  0.42 ± 0.03  0.33 ± 0.06  0.61 ± 0.06  0.83 ± 0.04   \n",
       "\n",
       "    auc  \n",
       "0  0.83  \n",
       "1  0.85  \n",
       "2  0.85  \n",
       "3  0.80  \n",
       "4  0.85  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#now test the models using this projected dataset\n",
    "pca = PCA(n_components=60)\n",
    "data_pca = pca.fit_transform(data_rescaled)\n",
    "df_pca = pd.DataFrame(data_pca)\n",
    "\n",
    "rfecv = RFECV(LogisticRegression(), step=1, scoring='f1', cv=10)\n",
    "rfecv = rfecv.fit(df_pca, labels)\n",
    "mask = rfecv.support_\n",
    "\n",
    "drop_features = []\n",
    "index = 0\n",
    "for val in mask:\n",
    "    if not val:\n",
    "        drop_features.append(index)\n",
    "    index += 1\n",
    "\n",
    "df_pca = df_pca.drop(drop_features, axis=1)\n",
    "print_stats(models, method, df_pca, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.34 ± 0.11</td>\n",
       "      <td>0.33 ± 0.11</td>\n",
       "      <td>0.35 ± 0.13</td>\n",
       "      <td>0.86 ± 0.03</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.42 ± 0.10</td>\n",
       "      <td>0.43 ± 0.07</td>\n",
       "      <td>0.41 ± 0.13</td>\n",
       "      <td>0.89 ± 0.01</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.39 ± 0.07</td>\n",
       "      <td>0.36 ± 0.10</td>\n",
       "      <td>0.43 ± 0.03</td>\n",
       "      <td>0.86 ± 0.03</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.36 ± 0.04</td>\n",
       "      <td>0.31 ± 0.06</td>\n",
       "      <td>0.43 ± 0.03</td>\n",
       "      <td>0.84 ± 0.03</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.44 ± 0.06</td>\n",
       "      <td>0.33 ± 0.07</td>\n",
       "      <td>0.69 ± 0.03</td>\n",
       "      <td>0.82 ± 0.04</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.34 ± 0.11  0.33 ± 0.11  0.35 ± 0.13  0.86 ± 0.03   \n",
       "1                  Voting  0.42 ± 0.10  0.43 ± 0.07  0.41 ± 0.13  0.89 ± 0.01   \n",
       "2                     MLP  0.39 ± 0.07  0.36 ± 0.10  0.43 ± 0.03  0.86 ± 0.03   \n",
       "3                AdaBoost  0.36 ± 0.04  0.31 ± 0.06  0.43 ± 0.03  0.84 ± 0.03   \n",
       "4  Support Vector Machine  0.44 ± 0.06  0.33 ± 0.07  0.69 ± 0.03  0.82 ± 0.04   \n",
       "\n",
       "    auc  \n",
       "0  0.76  \n",
       "1  0.82  \n",
       "2  0.81  \n",
       "3  0.76  \n",
       "4  0.84  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#now test the models using this projected dataset\n",
    "pca = PCA(n_components=40)\n",
    "data_pca = pca.fit_transform(data_rescaled)\n",
    "df_pca = pd.DataFrame(data_pca)\n",
    "\n",
    "rfecv = RFECV(LogisticRegression(), scoring='f1', step=1, cv=10)\n",
    "rfecv = rfecv.fit(df_pca, labels)\n",
    "mask = rfecv.support_\n",
    "\n",
    "drop_features = []\n",
    "index = 0\n",
    "for val in mask:\n",
    "    if not val:\n",
    "        drop_features.append(index)\n",
    "    index += 1\n",
    "\n",
    "df_pca = df_pca.drop(drop_features, axis=1)\n",
    "print_stats(models, method, df_pca, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.40 ± 0.10</td>\n",
       "      <td>0.39 ± 0.04</td>\n",
       "      <td>0.43 ± 0.17</td>\n",
       "      <td>0.88 ± 0.00</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.46 ± 0.10</td>\n",
       "      <td>0.58 ± 0.11</td>\n",
       "      <td>0.41 ± 0.13</td>\n",
       "      <td>0.91 ± 0.02</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.51 ± 0.02</td>\n",
       "      <td>0.43 ± 0.02</td>\n",
       "      <td>0.63 ± 0.07</td>\n",
       "      <td>0.88 ± 0.01</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.38 ± 0.06</td>\n",
       "      <td>0.35 ± 0.08</td>\n",
       "      <td>0.43 ± 0.03</td>\n",
       "      <td>0.86 ± 0.03</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.49 ± 0.02</td>\n",
       "      <td>0.42 ± 0.03</td>\n",
       "      <td>0.61 ± 0.07</td>\n",
       "      <td>0.87 ± 0.02</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method           f1    precision       recall     accuracy  \\\n",
       "0             Naive Bayes  0.40 ± 0.10  0.39 ± 0.04  0.43 ± 0.17  0.88 ± 0.00   \n",
       "1                  Voting  0.46 ± 0.10  0.58 ± 0.11  0.41 ± 0.13  0.91 ± 0.02   \n",
       "2                     MLP  0.51 ± 0.02  0.43 ± 0.02  0.63 ± 0.07  0.88 ± 0.01   \n",
       "3                AdaBoost  0.38 ± 0.06  0.35 ± 0.08  0.43 ± 0.03  0.86 ± 0.03   \n",
       "4  Support Vector Machine  0.49 ± 0.02  0.42 ± 0.03  0.61 ± 0.07  0.87 ± 0.02   \n",
       "\n",
       "    auc  \n",
       "0  0.77  \n",
       "1  0.83  \n",
       "2  0.85  \n",
       "3  0.78  \n",
       "4  0.87  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=60)\n",
    "data_pca = pca.fit_transform(data_rescaled)\n",
    "df_pca = pd.DataFrame(data_pca)\n",
    "\n",
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Voting': VotingClassifier(estimators=[('mlp', MLPClassifier(alpha=0.01)),\n",
    "                                            ('ada', AdaBoostClassifier(n_estimators=100, learning_rate=0.25)),\n",
    "                                            ('SVC', SVC(C=0.01, degree=2, gamma=1, kernel='poly', \n",
    "                                                        class_weight=None, probability=True)),\n",
    "                                            ('nb', GaussianNB())], voting='soft'),\n",
    "          'Perceptron': MLPClassifier(alpha=0.01),\n",
    "          'AdaBoost': AdaBoostClassifier(n_estimators=100, learning_rate=0.25),\n",
    "          'Support Vector Machine': SVC(C=1, gamma=0.001, kernel='linear', class_weight=None)}\n",
    "\n",
    "method = ['Naive Bayes', 'Voting', 'MLP', 'AdaBoost', 'Support Vector Machine']\n",
    "\n",
    "#now test the models using this projected dataset\n",
    "rfecv = RFECV(LogisticRegression(), step=1, scoring='f1', cv=10)\n",
    "rfecv = rfecv.fit(df_pca, labels)\n",
    "mask = rfecv.support_\n",
    "\n",
    "drop_features = []\n",
    "index = 0\n",
    "for val in mask:\n",
    "    if not val:\n",
    "        drop_features.append(index)\n",
    "    index += 1\n",
    "\n",
    "df_pca = df_pca.drop(drop_features, axis=1)\n",
    "print_stats(models, method, df_pca, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__activation': 'relu', 'model__alpha': 0.01, 'model__solver': 'adam'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#start with MLP\n",
    "mlp_cv = GridSearchCV(SMOTEClassifier(MLPClassifier()), param_grid={\n",
    "        'model__activation': ('logistic', 'tanh', 'relu'),\n",
    "        'model__solver': ('adam',),\n",
    "        'model__alpha': (0.0001, 0.001, 0.01, 0.1)}, scoring='f1', cv=10)\n",
    "\n",
    "mlp_cv.fit(df_pca, labels)\n",
    "mlp_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__activation</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.533922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.498885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.503233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.496904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.516899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.525838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.542613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.533052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.511300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.558595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.585411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.545025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__activation param_model__alpha  mean_test_score\n",
       "0                 logistic             0.0001         0.533922\n",
       "1                 logistic              0.001         0.498885\n",
       "2                 logistic               0.01         0.503233\n",
       "3                 logistic                0.1         0.496904\n",
       "4                     tanh             0.0001         0.516899\n",
       "5                     tanh              0.001         0.525838\n",
       "6                     tanh               0.01         0.542613\n",
       "7                     tanh                0.1         0.533052\n",
       "8                     relu             0.0001         0.511300\n",
       "9                     relu              0.001         0.558595\n",
       "10                    relu               0.01         0.585411\n",
       "11                    relu                0.1         0.545025"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = pd.DataFrame(mlp_cv.cv_results_)[['param_model__activation', 'param_model__alpha', 'mean_test_score']]\n",
    "lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now try SVM\n",
    "svm_cv = GridSearchCV(SMOTEClassifier(SVC()), param_grid={\n",
    "        'model__kernel': ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "        'model__degree': (2,3),\n",
    "        'model__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'model__gamma': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'model__class_weight': (None, 'balanced')}, scoring='f1', cv=10)\n",
    "\n",
    "svm_cv.fit(df_pca, labels)\n",
    "svm_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__base_estimator__max_depth': 2,\n",
       " 'model__learning_rate': 0.25,\n",
       " 'model__n_estimators': 100}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now try AdaBoost\n",
    "ada_cv = GridSearchCV(SMOTEClassifier(AdaBoostClassifier(base_estimator=DecisionTreeClassifier())), param_grid={\n",
    "        'model__base_estimator__max_depth': (1,2,3),\n",
    "        'model__n_estimators': (50,100, 200),\n",
    "        'model__learning_rate': (0.25, 0.5, 1)}, scoring='f1', cv=10)\n",
    "\n",
    "ada_cv.fit(df_pca, labels)\n",
    "ada_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['param_model__base_estimator'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-97b514a9bb66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m lol = pd.DataFrame(ada_cv.cv_results_)[['param_model__base_estimator', 'param_model__n_estimators', \n\u001b[0;32m----> 2\u001b[0;31m                                         'param_model__learning_rate','mean_test_score']]\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2679\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2680\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2722\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2723\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['param_model__base_estimator'] not in index\""
     ]
    }
   ],
   "source": [
    "lol = pd.DataFrame(ada_cv.cv_results_)[['param_model__base_estimator', 'param_model__n_estimators', \n",
    "                                        'param_model__learning_rate','mean_test_score']]\n",
    "lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__base_estimator__max_depth</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.386970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.359798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.430456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.388900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.395024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.410380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.381126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.360801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.393098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.429383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.499684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.445568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.373496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.449633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.415839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.351582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.474046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.375247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.437588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.389594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.325691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.364725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.393787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.438287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.394857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__base_estimator__max_depth param_model__n_estimators  \\\n",
       "0                                       1                        50   \n",
       "1                                       1                       100   \n",
       "2                                       1                       200   \n",
       "3                                       1                        50   \n",
       "4                                       1                       100   \n",
       "5                                       1                       200   \n",
       "6                                       1                        50   \n",
       "7                                       1                       100   \n",
       "8                                       1                       200   \n",
       "9                                       2                        50   \n",
       "10                                      2                       100   \n",
       "11                                      2                       200   \n",
       "12                                      2                        50   \n",
       "13                                      2                       100   \n",
       "14                                      2                       200   \n",
       "15                                      2                        50   \n",
       "16                                      2                       100   \n",
       "17                                      2                       200   \n",
       "18                                      3                        50   \n",
       "19                                      3                       100   \n",
       "20                                      3                       200   \n",
       "21                                      3                        50   \n",
       "22                                      3                       100   \n",
       "23                                      3                       200   \n",
       "24                                      3                        50   \n",
       "25                                      3                       100   \n",
       "26                                      3                       200   \n",
       "\n",
       "   param_model__learning_rate  mean_test_score  \n",
       "0                        0.25         0.386970  \n",
       "1                        0.25         0.359798  \n",
       "2                        0.25         0.430456  \n",
       "3                         0.5         0.388900  \n",
       "4                         0.5         0.395024  \n",
       "5                         0.5         0.410380  \n",
       "6                           1         0.381126  \n",
       "7                           1         0.360801  \n",
       "8                           1         0.393098  \n",
       "9                        0.25         0.429383  \n",
       "10                       0.25         0.499684  \n",
       "11                       0.25         0.445568  \n",
       "12                        0.5         0.373496  \n",
       "13                        0.5         0.449633  \n",
       "14                        0.5         0.415839  \n",
       "15                          1         0.351582  \n",
       "16                          1         0.474046  \n",
       "17                          1         0.386585  \n",
       "18                       0.25         0.375247  \n",
       "19                       0.25         0.437588  \n",
       "20                       0.25         0.389594  \n",
       "21                        0.5         0.325691  \n",
       "22                        0.5         0.364725  \n",
       "23                        0.5         0.393787  \n",
       "24                          1         0.438287  \n",
       "25                          1         0.358567  \n",
       "26                          1         0.394857  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = pd.DataFrame(ada_cv.cv_results_)[['param_model__base_estimator__max_depth', 'param_model__n_estimators', \n",
    "                                        'param_model__learning_rate','mean_test_score']]\n",
    "lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
