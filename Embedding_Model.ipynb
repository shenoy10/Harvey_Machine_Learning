{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ashwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ashwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora, models\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from process_tweet import *\n",
    "\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import random\n",
    "import time\n",
    "\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>Urgency</th>\n",
       "      <th>top0</th>\n",
       "      <th>top1</th>\n",
       "      <th>top2</th>\n",
       "      <th>top3</th>\n",
       "      <th>top4</th>\n",
       "      <th>top5</th>\n",
       "      <th>top6</th>\n",
       "      <th>top7</th>\n",
       "      <th>top8</th>\n",
       "      <th>top9</th>\n",
       "      <th>top10</th>\n",
       "      <th>top11</th>\n",
       "      <th>top12</th>\n",
       "      <th>top13</th>\n",
       "      <th>top14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>millions afghanistan even zero attack isis sym...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098502</td>\n",
       "      <td>0.089703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last post brother make social media phone go v...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>listen local officials epa help harvey respons...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314598</td>\n",
       "      <td>0.132971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258455</td>\n",
       "      <td>0.202309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>damn proud tirelessly help fellow texans affec...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088902</td>\n",
       "      <td>0.088699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help harvey disaster response help victims nat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211954</td>\n",
       "      <td>0.282543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Relevancy  Urgency  \\\n",
       "0  millions afghanistan even zero attack isis sym...          0        0   \n",
       "1  last post brother make social media phone go v...          2        1   \n",
       "2  listen local officials epa help harvey respons...          0        0   \n",
       "3  damn proud tirelessly help fellow texans affec...          3        0   \n",
       "4  help harvey disaster response help victims nat...          0        0   \n",
       "\n",
       "   top0      top1      top2      top3      top4      top5      top6      top7  \\\n",
       "0   0.0  0.326608  0.000000  0.098502  0.089703  0.000000  0.000000  0.000000   \n",
       "1   0.0  0.000000  0.267500  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.0  0.000000  0.314598  0.132971  0.000000  0.258455  0.202309  0.000000   \n",
       "3   0.0  0.000000  0.088902  0.088699  0.000000  0.110020  0.000000  0.154831   \n",
       "4   0.0  0.000000  0.211954  0.282543  0.000000  0.000000  0.000000  0.222220   \n",
       "\n",
       "       top8      top9     top10     top11  top12  top13     top14  \n",
       "0  0.158985  0.000000  0.088616  0.000000    0.0    0.0  0.191432  \n",
       "1  0.145833  0.106667  0.000000  0.106667    0.0    0.0  0.306667  \n",
       "2  0.000000  0.000000  0.000000  0.000000    0.0    0.0  0.000000  \n",
       "3  0.000000  0.410966  0.000000  0.000000    0.0    0.0  0.096582  \n",
       "4  0.000000  0.000000  0.109938  0.000000    0.0    0.0  0.106679  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/labeled_prelim_lda.csv')\n",
    "df = df.dropna()\n",
    "df.pop('Id')\n",
    "df = df.astype({'Relevancy':np.int32, 'Urgency':np.int32})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'millions afghanistan even zero attack isis sympathizers invest texas nation build harvey texasflood'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sym_spell = create_symspell(2,7,'data/frequency_dictionary_en_82_765.txt')\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "doc_sample = df['Text'][0]\n",
    "process_tweet(doc_sample, tknzr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty line\n"
     ]
    }
   ],
   "source": [
    "#list of embeddings\n",
    "vec_length = 50\n",
    "embeddings = np.zeros((1193514, vec_length))\n",
    "\n",
    "#two-way map, index->word and word->index\n",
    "glove = {}\n",
    "\n",
    "index = 0\n",
    "with open('data/glove.twitter.27B/glove.twitter.27B.%dd.txt' % vec_length) as f:\n",
    "    for l in f:\n",
    "        line = []\n",
    "        try:\n",
    "            line = l.split()\n",
    "            if len(line) != vec_length+1:\n",
    "                print('empty line')\n",
    "                continue\n",
    "            \n",
    "            word = line[0]\n",
    "            embeddings[index] = np.array(line[1:]).astype(np.float)\n",
    "            glove[index] = word\n",
    "            glove[word] = index\n",
    "            index += 1\n",
    "        except:\n",
    "            print(line)\n",
    "            print(index)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert columns to numpy arrays\n",
    "text = df['Text'].values\n",
    "relevancy = df['Relevancy'].values\n",
    "urgency = df['Urgency'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevancyClassifier(nn.Module):\n",
    "    def __init__(self, index, embeddings, embed_len, num_classes):\n",
    "        super(RelevancyClassifier, self).__init__()\n",
    "        self.hidden_size = 30\n",
    "        self.embed_len = embed_len\n",
    "        #print(embeddings.shape)\n",
    "        #self.embedding = nn.Embedding.from_pretrained(embeddings)\n",
    "        self.fc1 = nn.Linear(embed_len, self.hidden_size)\n",
    "        self.nl = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(self.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.nl(self.fc1(x)))\n",
    "\n",
    "def train_relevancy_classifier(train_exs, train_labels, embeddings, index):\n",
    "    try:\n",
    "        epochs = 100\n",
    "        lr = .0001\n",
    "        num_classes = 2\n",
    "        rc = RelevancyClassifier(index, embeddings, len(embeddings[0]), num_classes)\n",
    "        optimizer = optim.Adam(rc.parameters(), lr=lr)\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            ex_indices = [i for i in range(len(train_exs))]\n",
    "            random.shuffle(ex_indices)\n",
    "            total_loss = 0.0\n",
    "            num_tweets = len(ex_indices)\n",
    "            for idx in ex_indices:\n",
    "                cur_tweet = train_exs[idx]\n",
    "                cur_embed = []\n",
    "                for i in cur_tweet.split():\n",
    "                    if i in index:\n",
    "                        cur_embed.append(embeddings[index[i]])\n",
    "                if len(cur_embed) == 0:\n",
    "                    num_tweets -= 1\n",
    "                    continue\n",
    "                \n",
    "                x = torch.from_numpy(np.asarray(np.mean(cur_embed, axis=0)).reshape(1,vec_length)).float()\n",
    "                y = np.asarray(train_labels[idx]).reshape(1)\n",
    "                if y[0] > 0:\n",
    "                    y[0] = 1\n",
    "                y = torch.tensor(y).long()\n",
    "                rc.zero_grad()\n",
    "                probs = rc.forward(x)\n",
    "                cur_loss = loss(probs, y)\n",
    "                total_loss += cur_loss\n",
    "                cur_loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"Avg loss on epoch %i: %f\" % (epoch, total_loss/num_tweets))\n",
    "        return rc\n",
    "    except KeyboardInterrupt:\n",
    "        return rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'].values, relevancy, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss on epoch 0: 0.577541\n",
      "Avg loss on epoch 10: 0.471307\n",
      "Avg loss on epoch 20: 0.449612\n",
      "Avg loss on epoch 30: 0.436855\n",
      "Avg loss on epoch 40: 0.425467\n",
      "Avg loss on epoch 50: 0.415612\n",
      "Avg loss on epoch 60: 0.405068\n",
      "Avg loss on epoch 70: 0.394910\n",
      "Avg loss on epoch 80: 0.384393\n",
      "Avg loss on epoch 90: 0.375414\n"
     ]
    }
   ],
   "source": [
    "model = train_relevancy_classifier(X_train, y_train, embeddings, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.760163\n",
      "precision: 0.511111\n",
      "recall: 0.383333\n",
      "f1: 0.438095\n"
     ]
    }
   ],
   "source": [
    "val_tweets = X_test\n",
    "val_labels = y_test\n",
    "for i in range(len(val_labels)):\n",
    "    if val_labels[i] > 0:\n",
    "        val_labels[i] = 1\n",
    "\n",
    "num_correct = 0\n",
    "num_true_pos = 0\n",
    "num_false_pos = 0\n",
    "num_false_neg = 0\n",
    "\n",
    "for i in range(len(val_tweets)):\n",
    "    cur_embed = []\n",
    "    cur_tweet = val_tweets[i]\n",
    "    cur_label = val_labels[i]\n",
    "    for i in cur_tweet.split():\n",
    "        if i in glove:\n",
    "            cur_embed.append(embeddings[glove[i]])\n",
    "    if len(cur_embed) == 0:\n",
    "        continue\n",
    "    x = torch.from_numpy(np.asarray(np.mean(cur_embed, axis=0)).reshape(1,vec_length)).float()\n",
    "    probs = model.forward(x).detach().numpy().reshape(2)\n",
    "    pred_label = np.argmax(probs)\n",
    "    if pred_label == cur_label:\n",
    "        num_correct += 1\n",
    "        if pred_label > 0:\n",
    "            num_true_pos += 1\n",
    "    else:\n",
    "        if pred_label == 0:\n",
    "            num_false_neg += 1\n",
    "        else:\n",
    "            num_false_pos += 1\n",
    "\n",
    "accuracy = num_correct/len(val_tweets)\n",
    "precision = num_true_pos/(num_true_pos + num_false_pos)\n",
    "recall = num_true_pos/(num_true_pos + num_false_neg)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "\n",
    "print('accuracy: %f' % accuracy)\n",
    "print('precision: %f' % precision)\n",
    "print('recall: %f' % recall)\n",
    "print('f1: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only handles binary classification for now\n",
    "def tweets_to_df(df, labels, embeddings, glove):\n",
    "    \n",
    "    weights = []\n",
    "    index_omit = []\n",
    "    index = -1\n",
    "    tweets = df['Text']\n",
    "    \n",
    "    for i in range(vec_length+1):\n",
    "        weights.append([])\n",
    "    \n",
    "    for i in range(len(tweets)):\n",
    "        index += 1\n",
    "        cur_embed = []\n",
    "        cur_tweet = tweets[i]\n",
    "        cur_label = labels[i]\n",
    "        for i in cur_tweet.split():\n",
    "            if i in glove:\n",
    "                cur_embed.append(embeddings[glove[i]])\n",
    "        \n",
    "        if len(cur_embed) == 0:\n",
    "            #make sure we drop this row from the input dataframe\n",
    "            index_omit.append(index)\n",
    "            continue\n",
    "        \n",
    "        x = np.asarray(np.mean(cur_embed, axis=0))\n",
    "        \n",
    "        for j in range(vec_length):\n",
    "            weights[j].append(x[j])\n",
    "        weights[vec_length].append(0 if cur_label == 0 else 1)\n",
    "        #weights[vec_length].append(cur_label)\n",
    "        \n",
    "    df_pruned = df.drop(index_omit)\n",
    "    \n",
    "    #convert to dataframe\n",
    "    cols = {}\n",
    "    for i in range(vec_length):\n",
    "       cols['v' + str(i)] = weights[i]\n",
    "    \n",
    "    cols['class'] = weights[vec_length]\n",
    "    \n",
    "    df2 = pd.DataFrame(data=cols)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v40</th>\n",
       "      <th>v41</th>\n",
       "      <th>v42</th>\n",
       "      <th>v43</th>\n",
       "      <th>v44</th>\n",
       "      <th>v45</th>\n",
       "      <th>v46</th>\n",
       "      <th>v47</th>\n",
       "      <th>v48</th>\n",
       "      <th>v49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155161</td>\n",
       "      <td>0.263687</td>\n",
       "      <td>-0.029247</td>\n",
       "      <td>-0.204771</td>\n",
       "      <td>-0.086706</td>\n",
       "      <td>0.119640</td>\n",
       "      <td>-0.093732</td>\n",
       "      <td>-0.177305</td>\n",
       "      <td>0.228087</td>\n",
       "      <td>-0.533599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057220</td>\n",
       "      <td>-0.203605</td>\n",
       "      <td>0.035893</td>\n",
       "      <td>-0.323683</td>\n",
       "      <td>0.077375</td>\n",
       "      <td>-0.104995</td>\n",
       "      <td>0.097013</td>\n",
       "      <td>0.079060</td>\n",
       "      <td>0.138891</td>\n",
       "      <td>0.369817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.506732</td>\n",
       "      <td>0.533653</td>\n",
       "      <td>-0.236270</td>\n",
       "      <td>-0.220237</td>\n",
       "      <td>0.152508</td>\n",
       "      <td>-0.093731</td>\n",
       "      <td>0.910368</td>\n",
       "      <td>-0.188011</td>\n",
       "      <td>0.156793</td>\n",
       "      <td>-0.024209</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.003719</td>\n",
       "      <td>0.280569</td>\n",
       "      <td>-0.034819</td>\n",
       "      <td>-0.100392</td>\n",
       "      <td>0.275760</td>\n",
       "      <td>-0.321023</td>\n",
       "      <td>-0.030767</td>\n",
       "      <td>-0.124344</td>\n",
       "      <td>-0.230642</td>\n",
       "      <td>0.072494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616114</td>\n",
       "      <td>0.568701</td>\n",
       "      <td>-0.347945</td>\n",
       "      <td>-0.320448</td>\n",
       "      <td>0.147845</td>\n",
       "      <td>-0.314545</td>\n",
       "      <td>0.454590</td>\n",
       "      <td>-0.031889</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>-0.661508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412471</td>\n",
       "      <td>0.253620</td>\n",
       "      <td>0.302392</td>\n",
       "      <td>0.076902</td>\n",
       "      <td>0.062330</td>\n",
       "      <td>0.034372</td>\n",
       "      <td>0.041387</td>\n",
       "      <td>0.031561</td>\n",
       "      <td>-0.225155</td>\n",
       "      <td>0.007954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.402962</td>\n",
       "      <td>0.203641</td>\n",
       "      <td>-0.242108</td>\n",
       "      <td>-0.260091</td>\n",
       "      <td>-0.097311</td>\n",
       "      <td>-0.035554</td>\n",
       "      <td>0.515226</td>\n",
       "      <td>0.211987</td>\n",
       "      <td>-0.145409</td>\n",
       "      <td>-0.181648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169680</td>\n",
       "      <td>0.037749</td>\n",
       "      <td>0.240010</td>\n",
       "      <td>0.078180</td>\n",
       "      <td>0.026234</td>\n",
       "      <td>-0.069752</td>\n",
       "      <td>0.245466</td>\n",
       "      <td>0.028327</td>\n",
       "      <td>-0.201005</td>\n",
       "      <td>0.133578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.530228</td>\n",
       "      <td>0.428295</td>\n",
       "      <td>-0.506334</td>\n",
       "      <td>-0.411837</td>\n",
       "      <td>0.458561</td>\n",
       "      <td>-0.404194</td>\n",
       "      <td>0.540873</td>\n",
       "      <td>-0.137780</td>\n",
       "      <td>0.167950</td>\n",
       "      <td>-0.654720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351348</td>\n",
       "      <td>-0.081795</td>\n",
       "      <td>0.374603</td>\n",
       "      <td>-0.125783</td>\n",
       "      <td>0.285781</td>\n",
       "      <td>-0.053783</td>\n",
       "      <td>0.070025</td>\n",
       "      <td>0.046146</td>\n",
       "      <td>-0.097200</td>\n",
       "      <td>0.104830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v0        v1        v2        v3        v4        v5        v6  \\\n",
       "0  0.155161  0.263687 -0.029247 -0.204771 -0.086706  0.119640 -0.093732   \n",
       "1  0.506732  0.533653 -0.236270 -0.220237  0.152508 -0.093731  0.910368   \n",
       "2  0.616114  0.568701 -0.347945 -0.320448  0.147845 -0.314545  0.454590   \n",
       "3  0.402962  0.203641 -0.242108 -0.260091 -0.097311 -0.035554  0.515226   \n",
       "4  0.530228  0.428295 -0.506334 -0.411837  0.458561 -0.404194  0.540873   \n",
       "\n",
       "         v7        v8        v9    ...          v40       v41       v42  \\\n",
       "0 -0.177305  0.228087 -0.533599    ...    -0.057220 -0.203605  0.035893   \n",
       "1 -0.188011  0.156793 -0.024209    ...    -1.003719  0.280569 -0.034819   \n",
       "2 -0.031889  0.344140 -0.661508    ...    -0.412471  0.253620  0.302392   \n",
       "3  0.211987 -0.145409 -0.181648    ...    -0.169680  0.037749  0.240010   \n",
       "4 -0.137780  0.167950 -0.654720    ...    -0.351348 -0.081795  0.374603   \n",
       "\n",
       "        v43       v44       v45       v46       v47       v48       v49  \n",
       "0 -0.323683  0.077375 -0.104995  0.097013  0.079060  0.138891  0.369817  \n",
       "1 -0.100392  0.275760 -0.321023 -0.030767 -0.124344 -0.230642  0.072494  \n",
       "2  0.076902  0.062330  0.034372  0.041387  0.031561 -0.225155  0.007954  \n",
       "3  0.078180  0.026234 -0.069752  0.245466  0.028327 -0.201005  0.133578  \n",
       "4 -0.125783  0.285781 -0.053783  0.070025  0.046146 -0.097200  0.104830  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfv = tweets_to_df(df, relevancy, embeddings, glove)\n",
    "labels = dfv.pop('class')\n",
    "dfv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import * \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import *\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def average(x):\n",
    "    return sum(x)/len(x)\n",
    "\n",
    "def get_stats(model, X, y, cv, verbose=False):\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    auc = []\n",
    "        \n",
    "    cv_results = cross_validate(model, X, y, scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], \n",
    "                                cv=cv, return_train_score=False)\n",
    "    \n",
    "    if verbose:\n",
    "        print(cv_results)\n",
    "    \n",
    "    #now return the data\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron (0.76, 0.0381) (0.57, 0.1004) (0.42, 0.0448) (0.48, 0.0576) 0.77\n",
      "KNN (0.75, 0.0273) (0.53, 0.0643) (0.42, 0.0777) (0.46, 0.0572) 0.72\n",
      "AdaBoost (0.75, 0.0325) (0.52, 0.0756) (0.42, 0.0727) (0.46, 0.0610) 0.75\n",
      "Naive Bayes (0.70, 0.0387) (0.45, 0.0449) (0.69, 0.0728) (0.54, 0.0473) 0.76\n",
      "Voting (0.75, 0.0337) (0.52, 0.0567) (0.63, 0.0787) (0.57, 0.0569) 0.78\n"
     ]
    }
   ],
   "source": [
    "models = {'Perceptron': MLPClassifier(), 'KNN': KNeighborsClassifier(),\n",
    "         'AdaBoost': AdaBoostClassifier(),\n",
    "          'Naive Bayes': GaussianNB(),\n",
    "          'Voting': VotingClassifier(estimators=[('mlp', MLPClassifier()),\n",
    "                                            ('ada', AdaBoostClassifier()),\n",
    "                                            ('nb', GaussianNB())], voting='soft')}\n",
    "\n",
    "vals = []\n",
    "metric = []\n",
    "model_name = []\n",
    "\n",
    "X_new = SelectKBest(k=25).fit_transform(dfv, labels)\n",
    "\n",
    "cv = 10\n",
    "for k,v in models.items():\n",
    "    stats = get_stats(v, dfv, labels, cv)\n",
    "    accuracy_avg = np.average(stats['test_accuracy'])\n",
    "    accuracy_std = np.std(stats['test_accuracy'])\n",
    "    precision_avg = np.average(stats['test_precision'])\n",
    "    precision_std = np.std(stats['test_precision'])\n",
    "    recall_avg = np.average(stats['test_recall'])\n",
    "    recall_std = np.std(stats['test_recall'])\n",
    "    f1_avg = np.average(stats['test_f1'])\n",
    "    f1_std = np.std(stats['test_f1'])\n",
    "    auc_avg = np.average(stats['test_roc_auc'])\n",
    "    \n",
    "    print('%s (%.2f, %.4f) (%.2f, %.4f) (%.2f, %.4f) (%.2f, %.4f) %.2f' % \n",
    "          (k, accuracy_avg, accuracy_std, precision_avg, precision_std, recall_avg, \n",
    "               recall_std, f1_avg, f1_std, auc_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
