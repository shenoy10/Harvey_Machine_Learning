{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ashwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora, models\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = pd.read_csv('data/twitter_processed.csv')\n",
    "\n",
    "#just keep the text series (array of word arrays in string form)\n",
    "proc = proc['text']\n",
    "\n",
    "#now write a function to convert the string representation of a list into an actual list\n",
    "def string_to_list(s):\n",
    "    partial_list = s[1:-1].split(', ')\n",
    "    return list(map(lambda x: x[1:-1], partial_list))\n",
    "\n",
    "word_lists = []\n",
    "for s in proc:\n",
    "    word_lists.append(string_to_list(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 displace\n",
      "1 displacedpets\n",
      "2 dog\n",
      "3 find\n",
      "4 harvey\n",
      "5 help\n",
      "6 hurricane\n",
      "7 jeep\n",
      "8 jump\n",
      "9 link\n",
      "10 owner\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(word_lists)\n",
    "count = 0\n",
    "\n",
    "#now show the most frequently-tweeted words\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "\n",
    "#now filter out words that show up too infrequently or too frequently\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in word_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(bow_corpus, num_topics=2, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.103*\"hurricaneharvey\" + 0.038*\"hurricaneirma\" + 0.015*\"the\" + 0.013*\"houston\" + 0.013*\"amp\" + 0.012*\"texas\" + 0.010*\"via\" + 0.009*\"irma\" + 0.009*\"hurricane\" + 0.009*\"flood\"\n",
      "Topic: 1 Word: 0.088*\"hurricaneharvey\" + 0.034*\"help\" + 0.017*\"relief\" + 0.017*\"amp\" + 0.017*\"victims\" + 0.016*\"donate\" + 0.014*\"i\" + 0.012*\"affect\" + 0.009*\"support\" + 0.009*\"need\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp_model = models.HdpModel(bow_corpus, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in hdp_model.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
